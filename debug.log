2026-01-02 10:41:36,411 - INFO - Starting extraction process...
2026-01-02 10:41:36,411 - INFO - Connecting to Ollama at http://localhost:11434/v1...
2026-01-02 10:41:36,580 - INFO - Instructor client initialized.
2026-01-02 10:41:36,580 - INFO - Loading schema from queries.yaml...
2026-01-02 10:41:36,584 - INFO - Schema loaded successfully.
2026-01-02 10:41:36,584 - INFO - Found 2 PDF files to process.
2026-01-02 10:41:36,584 - INFO - Processing Acoustic differences between healthy and depressed people- a cross-situation study.pdf...
2026-01-02 10:41:36,584 - INFO - Extracting text from Acoustic differences between healthy and depressed people- a cross-situation study.pdf...
2026-01-02 10:41:36,623 - INFO - Extracted 57466 characters.
2026-01-02 10:41:36,623 - INFO - Sending extraction request for Acoustic differences between healthy and depressed people- a cross-situation study.pdf to model academic-extractor...
2026-01-02 10:42:29,799 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 500 Internal Server Error"
2026-01-02 10:42:29,799 - INFO - Retrying request to /chat/completions in 0.495726 seconds
2026-01-02 10:49:45,857 - INFO - Starting extraction process...
2026-01-02 10:49:45,858 - INFO - Connecting to Ollama at http://localhost:11434/v1...
2026-01-02 10:49:46,041 - INFO - Instructor client initialized.
2026-01-02 10:49:46,041 - INFO - Loading schema from queries.yaml...
2026-01-02 10:49:46,047 - INFO - Schema loaded successfully.
2026-01-02 10:49:46,047 - INFO - Found 2 PDF files to process.
2026-01-02 10:49:46,047 - INFO - Processing Acoustic differences between healthy and depressed people- a cross-situation study.pdf...
2026-01-02 10:49:46,047 - INFO - Extracting text from Acoustic differences between healthy and depressed people- a cross-situation study.pdf...
2026-01-02 10:49:46,097 - INFO - Extracted 57466 characters.
2026-01-02 10:49:46,097 - INFO - Sending extraction request for Acoustic differences between healthy and depressed people- a cross-situation study.pdf to model academic-extractor...
2026-01-02 10:54:28,665 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 10:54:28,669 - INFO - Extraction successful for Acoustic differences between healthy and depressed people- a cross-situation study.pdf.
2026-01-02 10:54:28,669 - INFO - Saved results to results/Acoustic differences between healthy and depressed people- a cross-situation study.json
2026-01-02 10:54:28,669 - INFO - Processing Voice Symptoms, Perceived Voice Control, and Common Mental Disorders in Elementary School Teachers.pdf...
2026-01-02 10:54:28,670 - INFO - Extracting text from Voice Symptoms, Perceived Voice Control, and Common Mental Disorders in Elementary School Teachers.pdf...
2026-01-02 10:54:28,703 - INFO - Extracted 35959 characters.
2026-01-02 10:54:28,704 - INFO - Sending extraction request for Voice Symptoms, Perceived Voice Control, and Common Mental Disorders in Elementary School Teachers.pdf to model academic-extractor...
2026-01-02 10:57:07,610 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 10:57:07,616 - INFO - Extraction successful for Voice Symptoms, Perceived Voice Control, and Common Mental Disorders in Elementary School Teachers.pdf.
2026-01-02 10:57:07,616 - INFO - Saved results to results/Voice Symptoms, Perceived Voice Control, and Common Mental Disorders in Elementary School Teachers.json
2026-01-02 11:08:15,813 - INFO - Starting extraction process...
2026-01-02 11:08:15,813 - INFO - Connecting to Ollama at http://localhost:11434/v1...
2026-01-02 11:08:15,957 - INFO - Instructor client initialized.
2026-01-02 11:08:15,957 - INFO - Loading schema from queries.yaml...
2026-01-02 11:08:15,963 - INFO - Schema loaded successfully.
2026-01-02 11:08:15,963 - INFO - Found 355 PDF files to process.
2026-01-02 11:08:15,963 - INFO - Processing Long term outcome of psychogenic voice disorders.pdf...
2026-01-02 11:08:15,963 - INFO - Extracting text from Long term outcome of psychogenic voice disorders.pdf...
2026-01-02 11:08:15,989 - INFO - Extracted 38047 characters.
2026-01-02 11:08:15,989 - INFO - Sending extraction request for Long term outcome of psychogenic voice disorders.pdf to model academic-extractor...
2026-01-02 11:08:41,978 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 500 Internal Server Error"
2026-01-02 11:08:41,978 - INFO - Retrying request to /chat/completions in 0.388123 seconds
2026-01-02 11:10:43,569 - INFO - Starting extraction process...
2026-01-02 11:10:43,570 - INFO - Connecting to Ollama at http://localhost:11434/v1...
2026-01-02 11:10:43,760 - INFO - Instructor client initialized.
2026-01-02 11:10:43,761 - INFO - Loading schema from queries.yaml...
2026-01-02 11:10:43,767 - INFO - Schema loaded successfully.
2026-01-02 11:10:43,769 - INFO - Found 355 PDF files to process.
2026-01-02 11:10:43,769 - INFO - Processing Long term outcome of psychogenic voice disorders.pdf...
2026-01-02 11:10:43,769 - INFO - Extracting text from Long term outcome of psychogenic voice disorders.pdf...
2026-01-02 11:10:43,803 - INFO - Extracted 38047 characters.
2026-01-02 11:10:43,803 - INFO - Sending extraction request for Long term outcome of psychogenic voice disorders.pdf to model academic-extractor...
2026-01-02 11:17:59,424 - INFO - Starting extraction process...
2026-01-02 11:17:59,424 - INFO - Connecting to Ollama at http://localhost:11434/v1...
2026-01-02 11:17:59,576 - INFO - Instructor client initialized.
2026-01-02 11:17:59,576 - INFO - Loading schema from queries.yaml...
2026-01-02 11:17:59,582 - INFO - Schema loaded successfully.
2026-01-02 11:17:59,582 - INFO - Found 355 PDF files to process.
2026-01-02 11:17:59,582 - INFO - Processing Long term outcome of psychogenic voice disorders.pdf...
2026-01-02 11:17:59,582 - INFO - Extracting text from Long term outcome of psychogenic voice disorders.pdf...
2026-01-02 11:17:59,607 - INFO - Extracted 38047 characters.
2026-01-02 11:17:59,607 - INFO - Sending extraction request for Long term outcome of psychogenic voice disorders.pdf to model academic-extractor...
2026-01-02 11:18:21,951 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 500 Internal Server Error"
2026-01-02 11:18:21,951 - INFO - Retrying request to /chat/completions in 0.484934 seconds
2026-01-02 11:27:28,540 - INFO - Starting extraction process...
2026-01-02 11:27:28,541 - INFO - Connecting to Ollama at http://localhost:11434/v1...
2026-01-02 11:27:28,717 - INFO - Instructor client initialized.
2026-01-02 11:27:28,717 - INFO - Loading schema from queries.yaml...
2026-01-02 11:27:28,723 - INFO - Schema loaded successfully.
2026-01-02 11:27:28,723 - INFO - Found 355 PDF files to process.
2026-01-02 11:27:28,723 - INFO - Processing Long term outcome of psychogenic voice disorders.pdf...
2026-01-02 11:27:28,723 - INFO - Extracting text from Long term outcome of psychogenic voice disorders.pdf...
2026-01-02 11:27:28,751 - INFO - Extracted 38047 characters.
2026-01-02 11:27:28,751 - INFO - Sending extraction request for Long term outcome of psychogenic voice disorders.pdf to model academic-extractor...
2026-01-02 11:29:13,565 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:29:13,569 - INFO - Extraction successful for Long term outcome of psychogenic voice disorders.pdf.
2026-01-02 11:29:13,569 - INFO - Saved results to results/Long term outcome of psychogenic voice disorders.json
2026-01-02 11:29:18,570 - INFO - Processing Emotional□Behavioral Indicators in Children and Adolescents With and Without Vocal Problems- Self-Evaluation and Parental Evaluation.pdf...
2026-01-02 11:29:18,570 - INFO - Extracting text from Emotional□Behavioral Indicators in Children and Adolescents With and Without Vocal Problems- Self-Evaluation and Parental Evaluation.pdf...
2026-01-02 11:29:18,649 - INFO - Extracted 46951 characters.
2026-01-02 11:29:18,649 - INFO - Sending extraction request for Emotional□Behavioral Indicators in Children and Adolescents With and Without Vocal Problems- Self-Evaluation and Parental Evaluation.pdf to model academic-extractor...
2026-01-02 11:31:14,566 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:31:14,597 - INFO - Extraction successful for Emotional□Behavioral Indicators in Children and Adolescents With and Without Vocal Problems- Self-Evaluation and Parental Evaluation.pdf.
2026-01-02 11:31:14,597 - INFO - Saved results to results/Emotional□Behavioral Indicators in Children and Adolescents With and Without Vocal Problems- Self-Evaluation and Parental Evaluation.json
2026-01-02 11:31:19,598 - INFO - Processing Two-year outcome of vagus nerve stimulation in treatment-resistant depression.pdf...
2026-01-02 11:31:19,598 - INFO - Extracting text from Two-year outcome of vagus nerve stimulation in treatment-resistant depression.pdf...
2026-01-02 11:31:19,665 - INFO - Extracted 43574 characters.
2026-01-02 11:31:19,665 - INFO - Sending extraction request for Two-year outcome of vagus nerve stimulation in treatment-resistant depression.pdf to model academic-extractor...
2026-01-02 11:33:32,509 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:33:32,510 - INFO - Extraction successful for Two-year outcome of vagus nerve stimulation in treatment-resistant depression.pdf.
2026-01-02 11:33:32,510 - INFO - Saved results to results/Two-year outcome of vagus nerve stimulation in treatment-resistant depression.json
2026-01-02 11:33:37,510 - INFO - Processing Prosody impairment in depression measured through acoustic analysis.pdf...
2026-01-02 11:33:37,510 - INFO - Extracting text from Prosody impairment in depression measured through acoustic analysis.pdf...
2026-01-02 11:33:37,557 - INFO - Extracted 26637 characters.
2026-01-02 11:33:37,557 - INFO - Sending extraction request for Prosody impairment in depression measured through acoustic analysis.pdf to model academic-extractor...
2026-01-02 11:34:50,003 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:34:50,004 - INFO - Extraction successful for Prosody impairment in depression measured through acoustic analysis.pdf.
2026-01-02 11:34:50,004 - INFO - Saved results to results/Prosody impairment in depression measured through acoustic analysis.json
2026-01-02 11:34:55,004 - INFO - Processing Demographics and coexisting tremor, cervical dystonia and vocal fold disorders in a group of patients with spasmodic dysphonia.pdf...
2026-01-02 11:34:55,004 - INFO - Extracting text from Demographics and coexisting tremor, cervical dystonia and vocal fold disorders in a group of patients with spasmodic dysphonia.pdf...
2026-01-02 11:34:55,053 - INFO - Extracted 27387 characters.
2026-01-02 11:34:55,053 - INFO - Sending extraction request for Demographics and coexisting tremor, cervical dystonia and vocal fold disorders in a group of patients with spasmodic dysphonia.pdf to model academic-extractor...
2026-01-02 11:36:20,004 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:36:20,005 - INFO - Extraction successful for Demographics and coexisting tremor, cervical dystonia and vocal fold disorders in a group of patients with spasmodic dysphonia.pdf.
2026-01-02 11:36:20,005 - INFO - Saved results to results/Demographics and coexisting tremor, cervical dystonia and vocal fold disorders in a group of patients with spasmodic dysphonia.json
2026-01-02 11:36:25,005 - INFO - Processing Update on Clinical Characteristics of Upper Airway Dyspnea- A Mixed Methods Study.pdf...
2026-01-02 11:36:25,006 - INFO - Extracting text from Update on Clinical Characteristics of Upper Airway Dyspnea- A Mixed Methods Study.pdf...
2026-01-02 11:36:25,058 - INFO - Extracted 45456 characters.
2026-01-02 11:36:25,058 - INFO - Sending extraction request for Update on Clinical Characteristics of Upper Airway Dyspnea- A Mixed Methods Study.pdf to model academic-extractor...
2026-01-02 11:38:10,148 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:38:10,149 - INFO - Extraction successful for Update on Clinical Characteristics of Upper Airway Dyspnea- A Mixed Methods Study.pdf.
2026-01-02 11:38:10,150 - INFO - Saved results to results/Update on Clinical Characteristics of Upper Airway Dyspnea- A Mixed Methods Study.json
2026-01-02 11:38:15,150 - INFO - Processing The relationship between depressive symptoms, quality of life, and swallowing function in head and neck cancer patients 1 year after definitive therapy.pdf...
2026-01-02 11:38:15,150 - INFO - Extracting text from The relationship between depressive symptoms, quality of life, and swallowing function in head and neck cancer patients 1 year after definitive therapy.pdf...
2026-01-02 11:38:15,200 - INFO - Extracted 36891 characters.
2026-01-02 11:38:15,200 - INFO - Sending extraction request for The relationship between depressive symptoms, quality of life, and swallowing function in head and neck cancer patients 1 year after definitive therapy.pdf to model academic-extractor...
2026-01-02 11:40:10,532 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:40:10,533 - INFO - Extraction successful for The relationship between depressive symptoms, quality of life, and swallowing function in head and neck cancer patients 1 year after definitive therapy.pdf.
2026-01-02 11:40:10,533 - INFO - Saved results to results/The relationship between depressive symptoms, quality of life, and swallowing function in head and neck cancer patients 1 year after definitive therapy.json
2026-01-02 11:40:15,534 - INFO - Processing Speech and voice disorders in patients with psychogenic movement disorders.pdf...
2026-01-02 11:40:15,534 - INFO - Extracting text from Speech and voice disorders in patients with psychogenic movement disorders.pdf...
2026-01-02 11:40:15,565 - INFO - Extracted 21310 characters.
2026-01-02 11:40:15,565 - INFO - Sending extraction request for Speech and voice disorders in patients with psychogenic movement disorders.pdf to model academic-extractor...
2026-01-02 11:41:22,591 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:41:22,592 - INFO - Extraction successful for Speech and voice disorders in patients with psychogenic movement disorders.pdf.
2026-01-02 11:41:22,592 - INFO - Saved results to results/Speech and voice disorders in patients with psychogenic movement disorders.json
2026-01-02 11:41:27,592 - INFO - Processing Prediction of acute and late responses to light therapy from vocal (pitch) and self-rated activation in seasonal affective disorder.pdf...
2026-01-02 11:41:27,592 - INFO - Extracting text from Prediction of acute and late responses to light therapy from vocal (pitch) and self-rated activation in seasonal affective disorder.pdf...
2026-01-02 11:41:27,642 - INFO - Extracted 35220 characters.
2026-01-02 11:41:27,642 - INFO - Sending extraction request for Prediction of acute and late responses to light therapy from vocal (pitch) and self-rated activation in seasonal affective disorder.pdf to model academic-extractor...
2026-01-02 11:43:00,100 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:43:00,101 - INFO - Extraction successful for Prediction of acute and late responses to light therapy from vocal (pitch) and self-rated activation in seasonal affective disorder.pdf.
2026-01-02 11:43:00,101 - INFO - Saved results to results/Prediction of acute and late responses to light therapy from vocal (pitch) and self-rated activation in seasonal affective disorder.json
2026-01-02 11:43:05,101 - INFO - Processing Voice quality in depression.pdf...
2026-01-02 11:43:05,101 - INFO - Extracting text from Voice quality in depression.pdf...
2026-01-02 11:43:05,113 - INFO - Extracted 12553 characters.
2026-01-02 11:43:05,113 - INFO - Sending extraction request for Voice quality in depression.pdf to model academic-extractor...
2026-01-02 11:43:53,597 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:43:53,598 - INFO - Extraction successful for Voice quality in depression.pdf.
2026-01-02 11:43:53,598 - INFO - Saved results to results/Voice quality in depression.json
2026-01-02 11:43:58,599 - INFO - Processing Acoustic correlates of vocal effort- External factors and personality traits.pdf...
2026-01-02 11:43:58,599 - INFO - Extracting text from Acoustic correlates of vocal effort- External factors and personality traits.pdf...
2026-01-02 11:43:58,628 - INFO - Extracted 21544 characters.
2026-01-02 11:43:58,629 - INFO - Sending extraction request for Acoustic correlates of vocal effort- External factors and personality traits.pdf to model academic-extractor...
2026-01-02 11:45:07,894 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:45:07,894 - INFO - Extraction successful for Acoustic correlates of vocal effort- External factors and personality traits.pdf.
2026-01-02 11:45:07,894 - INFO - Saved results to results/Acoustic correlates of vocal effort- External factors and personality traits.json
2026-01-02 11:45:12,895 - INFO - Processing Long Term Health-Related Quality of Life with Differentiated Thyroid Cancer in Goiter Endemic Area.pdf...
2026-01-02 11:45:12,895 - INFO - Extracting text from Long Term Health-Related Quality of Life with Differentiated Thyroid Cancer in Goiter Endemic Area.pdf...
2026-01-02 11:45:12,920 - INFO - Extracted 29604 characters.
2026-01-02 11:45:12,920 - INFO - Sending extraction request for Long Term Health-Related Quality of Life with Differentiated Thyroid Cancer in Goiter Endemic Area.pdf to model academic-extractor...
2026-01-02 11:46:51,401 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:46:51,402 - INFO - Extraction successful for Long Term Health-Related Quality of Life with Differentiated Thyroid Cancer in Goiter Endemic Area.pdf.
2026-01-02 11:46:51,402 - INFO - Saved results to results/Long Term Health-Related Quality of Life with Differentiated Thyroid Cancer in Goiter Endemic Area.json
2026-01-02 11:46:56,402 - INFO - Processing Effect of an online Workplace Vocal Health and Low Stress Levels Promotion Program implemented in a Colombian university during COVID-19 pandemic.pdf...
2026-01-02 11:46:56,402 - INFO - Extracting text from Effect of an online Workplace Vocal Health and Low Stress Levels Promotion Program implemented in a Colombian university during COVID-19 pandemic.pdf...
2026-01-02 11:46:56,468 - INFO - Extracted 40202 characters.
2026-01-02 11:46:56,468 - INFO - Sending extraction request for Effect of an online Workplace Vocal Health and Low Stress Levels Promotion Program implemented in a Colombian university during COVID-19 pandemic.pdf to model academic-extractor...
2026-01-02 11:48:40,867 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:48:40,868 - INFO - Extraction successful for Effect of an online Workplace Vocal Health and Low Stress Levels Promotion Program implemented in a Colombian university during COVID-19 pandemic.pdf.
2026-01-02 11:48:40,868 - INFO - Saved results to results/Effect of an online Workplace Vocal Health and Low Stress Levels Promotion Program implemented in a Colombian university during COVID-19 pandemic.json
2026-01-02 11:48:45,869 - INFO - Processing Quality of life indicators according to voice disorders and voice-related conditions.pdf...
2026-01-02 11:48:45,869 - INFO - Extracting text from Quality of life indicators according to voice disorders and voice-related conditions.pdf...
2026-01-02 11:48:45,917 - INFO - Extracted 33943 characters.
2026-01-02 11:48:45,917 - INFO - Sending extraction request for Quality of life indicators according to voice disorders and voice-related conditions.pdf to model academic-extractor...
2026-01-02 11:50:10,352 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:50:10,357 - INFO - Extraction successful for Quality of life indicators according to voice disorders and voice-related conditions.pdf.
2026-01-02 11:50:10,357 - INFO - Saved results to results/Quality of life indicators according to voice disorders and voice-related conditions.json
2026-01-02 11:50:15,358 - INFO - Processing Validity and reliability of nonverbal voice measures as indicators of stressor-provoked anxiety.pdf...
2026-01-02 11:50:15,358 - INFO - Extracting text from Validity and reliability of nonverbal voice measures as indicators of stressor-provoked anxiety.pdf...
2026-01-02 11:50:15,385 - INFO - Extracted 41605 characters.
2026-01-02 11:50:15,385 - INFO - Sending extraction request for Validity and reliability of nonverbal voice measures as indicators of stressor-provoked anxiety.pdf to model academic-extractor...
2026-01-02 11:51:59,494 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:51:59,495 - INFO - Extraction successful for Validity and reliability of nonverbal voice measures as indicators of stressor-provoked anxiety.pdf.
2026-01-02 11:51:59,495 - INFO - Saved results to results/Validity and reliability of nonverbal voice measures as indicators of stressor-provoked anxiety.json
2026-01-02 11:52:04,496 - INFO - Processing Taking a Closer Look at Social Performance in Childhood Social Anxiety Disorder- Biopsychosocial Context Considerations and Effects of Cognitive Behavior Therapy.pdf...
2026-01-02 11:52:04,496 - INFO - Extracting text from Taking a Closer Look at Social Performance in Childhood Social Anxiety Disorder- Biopsychosocial Context Considerations and Effects of Cognitive Behavior Therapy.pdf...
2026-01-02 11:52:04,534 - INFO - Extracted 54647 characters.
2026-01-02 11:52:04,534 - INFO - Sending extraction request for Taking a Closer Look at Social Performance in Childhood Social Anxiety Disorder- Biopsychosocial Context Considerations and Effects of Cognitive Behavior Therapy.pdf to model academic-extractor...
2026-01-02 11:54:31,840 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:54:51,002 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:54:51,003 - INFO - Extraction successful for Taking a Closer Look at Social Performance in Childhood Social Anxiety Disorder- Biopsychosocial Context Considerations and Effects of Cognitive Behavior Therapy.pdf.
2026-01-02 11:54:51,003 - INFO - Saved results to results/Taking a Closer Look at Social Performance in Childhood Social Anxiety Disorder- Biopsychosocial Context Considerations and Effects of Cognitive Behavior Therapy.json
2026-01-02 11:54:56,004 - INFO - Processing Voice pitch measurements in schizophrenia and depression.pdf...
2026-01-02 11:54:56,004 - INFO - Extracting text from Voice pitch measurements in schizophrenia and depression.pdf...
2026-01-02 11:54:56,016 - INFO - Extracted 12121 characters.
2026-01-02 11:54:56,016 - INFO - Sending extraction request for Voice pitch measurements in schizophrenia and depression.pdf to model academic-extractor...
2026-01-02 11:55:41,513 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:55:41,514 - INFO - Extraction successful for Voice pitch measurements in schizophrenia and depression.pdf.
2026-01-02 11:55:41,515 - INFO - Saved results to results/Voice pitch measurements in schizophrenia and depression.json
2026-01-02 11:55:46,515 - INFO - Processing Vocal Acoustic Features as Potential Biomarkers for Identifying□Diagnosing Depression- A Cross-Sectional Study.pdf...
2026-01-02 11:55:46,515 - INFO - Extracting text from Vocal Acoustic Features as Potential Biomarkers for Identifying□Diagnosing Depression- A Cross-Sectional Study.pdf...
2026-01-02 11:55:46,547 - INFO - Extracted 44518 characters.
2026-01-02 11:55:46,547 - INFO - Sending extraction request for Vocal Acoustic Features as Potential Biomarkers for Identifying□Diagnosing Depression- A Cross-Sectional Study.pdf to model academic-extractor...
2026-01-02 11:57:44,562 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 11:57:44,563 - INFO - Extraction successful for Vocal Acoustic Features as Potential Biomarkers for Identifying□Diagnosing Depression- A Cross-Sectional Study.pdf.
2026-01-02 11:57:44,563 - INFO - Saved results to results/Vocal Acoustic Features as Potential Biomarkers for Identifying□Diagnosing Depression- A Cross-Sectional Study.json
2026-01-02 11:57:49,563 - INFO - Processing Analysis of shyness on vocal handicap perceived in school teachers.pdf...
2026-01-02 11:57:49,564 - INFO - Extracting text from Analysis of shyness on vocal handicap perceived in school teachers.pdf...
2026-01-02 11:57:49,628 - INFO - Extracted 29444 characters.
2026-01-02 11:57:49,628 - INFO - Sending extraction request for Analysis of shyness on vocal handicap perceived in school teachers.pdf to model academic-extractor...
2026-01-02 11:58:22,317 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 500 Internal Server Error"
2026-01-02 11:58:22,317 - INFO - Retrying request to /chat/completions in 0.425812 seconds
2026-01-02 12:11:07,405 - INFO - Starting extraction process...
2026-01-02 12:11:07,405 - INFO - Connecting to Ollama at http://localhost:11434/v1...
2026-01-02 12:11:07,579 - INFO - Instructor client initialized.
2026-01-02 12:11:07,579 - INFO - Loading schema from queries.yaml...
2026-01-02 12:11:07,585 - INFO - Schema loaded successfully.
2026-01-02 12:11:07,585 - INFO - Found 355 PDF files to process.
2026-01-02 12:11:07,585 - INFO - Processing Long term outcome of psychogenic voice disorders.pdf...
2026-01-02 12:11:07,585 - INFO - Extracting text from Long term outcome of psychogenic voice disorders.pdf...
2026-01-02 12:11:07,612 - INFO - Extracted 38047 characters.
2026-01-02 12:11:07,613 - INFO - Sending extraction request for Long term outcome of psychogenic voice disorders.pdf to model academic-extractor...
2026-01-02 12:11:59,089 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 500 Internal Server Error"
2026-01-02 12:11:59,090 - INFO - Retrying request to /chat/completions in 0.481582 seconds
2026-01-02 12:17:06,815 - INFO - Starting extraction process...
2026-01-02 12:17:06,815 - INFO - Connecting to Ollama at http://localhost:11434/v1...
2026-01-02 12:17:06,994 - INFO - Instructor client initialized.
2026-01-02 12:17:06,994 - INFO - Loading schema from queries.yaml...
2026-01-02 12:17:07,001 - INFO - Schema loaded successfully.
2026-01-02 12:17:07,001 - INFO - Found 355 PDF files to process.
2026-01-02 12:17:07,001 - INFO - Processing A Comparative Study of Iranian Female Primary School Teachers' Quality of Life With and Without Voice Complaints.pdf...
2026-01-02 12:17:07,001 - INFO - Extracting text from A Comparative Study of Iranian Female Primary School Teachers' Quality of Life With and Without Voice Complaints.pdf...
2026-01-02 12:17:07,042 - INFO - Extracted 25454 characters (approx 6363 tokens).
2026-01-02 12:17:07,042 - INFO - Extraction attempt 1/5 for A Comparative Study of Iranian Female Primary School Teachers' Quality of Life With and Without Voice Complaints.pdf...
2026-01-02 12:18:31,148 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 12:18:31,152 - INFO - Extraction successful for A Comparative Study of Iranian Female Primary School Teachers' Quality of Life With and Without Voice Complaints.pdf.
2026-01-02 12:18:31,152 - INFO - Saved results to results/A Comparative Study of Iranian Female Primary School Teachers' Quality of Life With and Without Voice Complaints.json
2026-01-02 12:18:41,152 - INFO - Processing A Survey of Vocal Health in Carnatic Singing Students.pdf...
2026-01-02 12:18:41,152 - INFO - Extracting text from A Survey of Vocal Health in Carnatic Singing Students.pdf...
2026-01-02 12:18:41,181 - INFO - Extracted 48607 characters (approx 12151 tokens).
2026-01-02 12:18:41,181 - INFO - Extraction attempt 1/5 for A Survey of Vocal Health in Carnatic Singing Students.pdf...
2026-01-02 12:20:35,092 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 12:20:35,093 - INFO - Extraction successful for A Survey of Vocal Health in Carnatic Singing Students.pdf.
2026-01-02 12:20:35,093 - INFO - Saved results to results/A Survey of Vocal Health in Carnatic Singing Students.json
2026-01-02 12:20:45,094 - INFO - Processing A comparative study of psychological aspects of recurring and non-recurring functional aphonias.pdf...
2026-01-02 12:20:45,094 - INFO - Extracting text from A comparative study of psychological aspects of recurring and non-recurring functional aphonias.pdf...
2026-01-02 12:20:45,140 - INFO - Extracted 21538 characters (approx 5384 tokens).
2026-01-02 12:20:45,140 - INFO - Extraction attempt 1/5 for A comparative study of psychological aspects of recurring and non-recurring functional aphonias.pdf...
2026-01-02 12:21:52,388 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 12:21:52,389 - INFO - Extraction successful for A comparative study of psychological aspects of recurring and non-recurring functional aphonias.pdf.
2026-01-02 12:21:52,389 - INFO - Saved results to results/A comparative study of psychological aspects of recurring and non-recurring functional aphonias.json
2026-01-02 12:22:02,390 - INFO - Processing A comparison of clinical ratings with vocal acoustic measures of flat affect and alogia.pdf...
2026-01-02 12:22:02,390 - INFO - Extracting text from A comparison of clinical ratings with vocal acoustic measures of flat affect and alogia.pdf...
2026-01-02 12:22:02,442 - INFO - Extracted 36669 characters (approx 9167 tokens).
2026-01-02 12:22:02,442 - INFO - Extraction attempt 1/5 for A comparison of clinical ratings with vocal acoustic measures of flat affect and alogia.pdf...
2026-01-02 12:23:36,920 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 12:23:36,921 - INFO - Extraction successful for A comparison of clinical ratings with vocal acoustic measures of flat affect and alogia.pdf.
2026-01-02 12:23:36,921 - INFO - Saved results to results/A comparison of clinical ratings with vocal acoustic measures of flat affect and alogia.json
2026-01-02 12:23:46,921 - INFO - Processing A cross sectional study on the vocal handicap index applied to a sample of teachers in nurseries and primary school.pdf...
2026-01-02 12:23:46,921 - INFO - Extracting text from A cross sectional study on the vocal handicap index applied to a sample of teachers in nurseries and primary school.pdf...
2026-01-02 12:23:46,967 - INFO - Extracted 19467 characters (approx 4866 tokens).
2026-01-02 12:23:46,967 - INFO - Extraction attempt 1/5 for A cross sectional study on the vocal handicap index applied to a sample of teachers in nurseries and primary school.pdf...
2026-01-02 12:24:53,060 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 12:24:53,060 - INFO - Extraction successful for A cross sectional study on the vocal handicap index applied to a sample of teachers in nurseries and primary school.pdf.
2026-01-02 12:24:53,060 - INFO - Saved results to results/A cross sectional study on the vocal handicap index applied to a sample of teachers in nurseries and primary school.json
2026-01-02 12:25:03,061 - INFO - Processing A generalizable speech emotion recognition model reveals depression and remission.pdf...
2026-01-02 12:25:03,061 - INFO - Extracting text from A generalizable speech emotion recognition model reveals depression and remission.pdf...
2026-01-02 12:25:03,223 - INFO - Extracted 62298 characters (approx 15574 tokens).
2026-01-02 12:25:03,224 - INFO - Extraction attempt 1/5 for A generalizable speech emotion recognition model reveals depression and remission.pdf...
2026-01-02 12:27:51,046 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 12:29:06,085 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2026-01-02 12:29:06,085 - INFO - Extraction successful for A generalizable speech emotion recognition model reveals depression and remission.pdf.
2026-01-02 12:29:06,086 - INFO - Saved results to results/A generalizable speech emotion recognition model reveals depression and remission.json
2026-01-02 12:29:16,086 - INFO - Processing A new artificial intelligence-based clinical decision support system for diagnosis of major psychiatric diseases based on voice analysis.pdf...
2026-01-02 12:29:16,086 - INFO - Extracting text from A new artificial intelligence-based clinical decision support system for diagnosis of major psychiatric diseases based on voice analysis.pdf...
2026-01-02 12:29:16,159 - INFO - Extracted 45738 characters (approx 11434 tokens).
2026-01-02 12:29:16,159 - INFO - Extraction attempt 1/5 for A new artificial intelligence-based clinical decision support system for diagnosis of major psychiatric diseases based on voice analysis.pdf...
2026-01-02 12:29:50,304 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 500 Internal Server Error"
2026-01-02 12:29:50,305 - INFO - Retrying request to /chat/completions in 0.499303 seconds
2026-01-02 12:58:04,088 - __main__ - INFO - Starting extraction process...
2026-01-02 12:58:04,088 - __main__ - DEBUG - Memory Usage: RSS=89.41 MB, VMS=139.43 MB
2026-01-02 12:58:04,088 - __main__ - INFO - Connecting to Ollama at http://localhost:11434/v1...
2026-01-02 12:58:04,253 - instructor - DEBUG - Patching `client.chat.completions.create` with mode=<Mode.JSON: 'json_mode'>
2026-01-02 12:58:04,253 - __main__ - INFO - Instructor client initialized.
2026-01-02 12:58:04,253 - __main__ - INFO - Loading schema from queries.yaml...
2026-01-02 12:58:04,259 - __main__ - INFO - Schema loaded successfully.
2026-01-02 12:58:04,259 - __main__ - INFO - Found 355 PDF files to process.
2026-01-02 12:58:04,259 - __main__ - INFO - Skipping A Comparative Study of Iranian Female Primary School Teachers' Quality of Life With and Without Voice Complaints.pdf - results already exist at results/A Comparative Study of Iranian Female Primary School Teachers' Quality of Life With and Without Voice Complaints.json
2026-01-02 12:58:04,259 - __main__ - INFO - Skipping A Survey of Vocal Health in Carnatic Singing Students.pdf - results already exist at results/A Survey of Vocal Health in Carnatic Singing Students.json
2026-01-02 12:58:04,259 - __main__ - INFO - Skipping A comparative study of psychological aspects of recurring and non-recurring functional aphonias.pdf - results already exist at results/A comparative study of psychological aspects of recurring and non-recurring functional aphonias.json
2026-01-02 12:58:04,259 - __main__ - INFO - Skipping A comparison of clinical ratings with vocal acoustic measures of flat affect and alogia.pdf - results already exist at results/A comparison of clinical ratings with vocal acoustic measures of flat affect and alogia.json
2026-01-02 12:58:04,259 - __main__ - INFO - Skipping A cross sectional study on the vocal handicap index applied to a sample of teachers in nurseries and primary school.pdf - results already exist at results/A cross sectional study on the vocal handicap index applied to a sample of teachers in nurseries and primary school.json
2026-01-02 12:58:04,259 - __main__ - INFO - Skipping A generalizable speech emotion recognition model reveals depression and remission.pdf - results already exist at results/A generalizable speech emotion recognition model reveals depression and remission.json
2026-01-02 12:58:04,259 - __main__ - INFO - Processing A new artificial intelligence-based clinical decision support system for diagnosis of major psychiatric diseases based on voice analysis.pdf...
2026-01-02 12:58:04,260 - __main__ - DEBUG - Memory Usage: RSS=98.09 MB, VMS=147.48 MB
2026-01-02 12:58:04,260 - __main__ - INFO - Extracting text from A new artificial intelligence-based clinical decision support system for diagnosis of major psychiatric diseases based on voice analysis.pdf...
2026-01-02 12:58:04,260 - ingest - DEBUG - Opening PDF: ./pdfs/A new artificial intelligence-based clinical decision support system for diagnosis of major psychiatric diseases based on voice analysis.pdf
2026-01-02 12:58:04,261 - ingest - DEBUG - Extracting page 1/11
2026-01-02 12:58:04,308 - ingest - DEBUG - Extracting page 10/11
2026-01-02 12:58:04,311 - ingest - DEBUG - Extracting page 11/11
2026-01-02 12:58:04,313 - __main__ - INFO - Extracted 45738 characters (approx 11434 tokens).
2026-01-02 12:58:04,313 - __main__ - DEBUG - First 500 characters of text: 489
INTRODUCTION
Mental illnesses are common illnesses characterized 
by a clinically significant disturbance in an individual’s 
cognition, emotional regulation, or behavior. It has been 
reported that approximately 970 million people world­
wide are currently affected by one or more mental dis­
orders, with an expected increase in the future (WHO, 
2022). Psychiatric disorders are predominantly chronic 
and have a substantial impact on the global economy, 
leading to decreased work performance...
2026-01-02 12:58:04,313 - __main__ - DEBUG - Memory Usage: RSS=106.19 MB, VMS=151.49 MB
2026-01-02 12:58:04,313 - __main__ - INFO - Extraction attempt 1/5 for A new artificial intelligence-based clinical decision support system for diagnosis of major psychiatric diseases based on voice analysis.pdf...
2026-01-02 12:58:04,313 - __main__ - DEBUG - Sending payload of size 45738 chars to model academic-extractor
2026-01-02 12:58:04,313 - __main__ - DEBUG - Memory Usage: RSS=106.19 MB, VMS=151.49 MB
2026-01-02 12:58:04,316 - instructor - DEBUG - Instructor Request: mode.value='json_mode', response_model=<class 'schema_engine.AcademicPaperExtraction'>, new_kwargs={'messages': [{'role': 'system', 'content': 'You are an expert academic data extractor.\n\n\n        As a genius expert, your task is to understand the content and provide\n        the parsed objects in json that match the following json_schema:\n\n\n        {\n  "properties": {\n    "title": {\n      "description": "What is the complete title of this academic paper? (Hint: The title is usually at the top of the first page in large, bold text. It may span multiple lines.) [Examples: Input: Digital Phenotype for Childhood Internalizing Disorders: Less Positive Play and Promise for a Brief Assessment Battery -> Output: Digital Phenotype for Childhood Internalizing Disorders: Less Positive Play and Promise for a Brief Assessment Battery]",\n      "title": "Title",\n      "type": "string"\n    },\n    "authors": {\n      "description": "List all authors of this paper in the order they appear, including their full names. (Hint: Authors are typically listed below the title, often with affiliations. Include all authors even if there are many.) [Examples: Input: John Smith, Jane Doe, Robert Johnson -> Output: [\'John Smith\', \'Jane Doe\', \'Robert Johnson\']]",\n      "items": {\n        "type": "string"\n      },\n      "title": "Authors",\n      "type": "array"\n    },\n    "first_author": {\n      "description": "Who is the first author of this paper? (Hint: The first author is typically the lead researcher and appears first in the author list.)",\n      "title": "First Author",\n      "type": "string"\n    },\n    "corresponding_author": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Who is the corresponding author? Look for email addresses or \'Corresponding author\' labels. (Hint: The corresponding author usually has an email address listed or is marked with an asterisk or \'Corresponding author\' notation.)",\n      "title": "Corresponding Author"\n    },\n    "first_author_department": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "What department or institution is the first author affiliated with? (Hint: Look for institutional affiliations listed with the first author\'s name. This is usually found below the author names or in the author information section.) [Examples: Input: Department of Psychology, University of California -> Output: Department of Psychology, University of California]",\n      "title": "First Author Department"\n    },\n    "corresponding_author_department": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "What department or institution is the corresponding author affiliated with? (Hint: Look for institutional affiliations listed with the corresponding author\'s name. This is usually found below the author names or in the author information section.) [Examples: Input: Department of Psychiatry, Harvard Medical School -> Output: Department of Psychiatry, Harvard Medical School]",\n      "title": "Corresponding Author Department"\n    },\n    "research_method": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "What research methodology was used in this study? (Hint: Look for sections labeled \'Methods\', \'Methodology\', or \'Study Design\'. Common methods include experimental, observational, survey, case study, etc.) [Examples: Input: This was a randomized controlled trial -> Output: Randomized controlled trial]",\n      "title": "Research Method"\n    },\n    "sample_size": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "How many participants or subjects were included in this study? (Hint: Look for numbers in the Methods section or Results section. It might be stated as \'N = 100\' or \'100 participants\'.) [Examples: Input: A total of 150 participants were recruited -> Output: 150 participants]",\n      "title": "Sample Size"\n    },\n    "study_population": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Who were the study participants? Describe the population studied. (Hint: Look in the Methods section for participant descriptions, including age, gender, demographics, or specific groups studied.) [Examples: Input: Children aged 8-12 years with internalizing disorders -> Output: Children aged 8-12 years with internalizing disorders]",\n      "title": "Study Population"\n    },\n    "statistical_methods": {\n      "anyOf": [\n        {\n          "items": {\n            "type": "string"\n          },\n          "type": "array"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "What statistical methods or analyses were used in this study? (Hint: Look in the Methods or Results section for statistical tests mentioned, such as t-tests, ANOVA, regression, etc.) [Examples: Input: We used t-tests and ANOVA for group comparisons -> Output: [\'t-tests\', \'ANOVA\']]",\n      "title": "Statistical Methods"\n    },\n    "main_findings": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "What are the main findings or results of this study? (Hint: Look in the Results section or Conclusion section for key findings. Focus on the most important results.) [Examples: Input: The study found significant differences in digital behavior between groups -> Output: Significant differences in digital behavior were found between groups]",\n      "title": "Main Findings"\n    },\n    "limitations": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "What are the main limitations of this study? (Hint: Look in the Results section or Conclusion section for limitations.) [Examples: Input: The study found significant differences in digital behavior between groups -> Output: Significant differences in digital behavior were found between groups]",\n      "title": "Limitations"\n    }\n  },\n  "required": [\n    "title",\n    "authors",\n    "first_author"\n  ],\n  "title": "AcademicPaperExtraction",\n  "type": "object"\n}\n\n        Make sure to return an instance of the JSON, not the schema itself\n'}, {'role': 'user', 'content': 'Extract data from this paper:\n\n489\nINTRODUCTION\nMental illnesses are common illnesses characterized \nby a clinically significant disturbance in an individual’s \ncognition, emotional regulation, or behavior. It has been \nreported that approximately 970 million people world\xad\nwide are currently affected by one or more mental dis\xad\norders, with an expected increase in the future (WHO, \n2022). Psychiatric disorders are predominantly chronic \nand have a substantial impact on the global economy, \nleading to decreased work performance and high treat\xad\nment costs (Jarman et al. 2016). Although these disorders \ncan be treated and symptom improvement is possible with \naccurate diagnosis, the presence of biological and clini\xad\ncal heterogeneity, coupled with the absence of diagnostic \nbiomarkers, makes the diagnostic process challenging \n(Bedi et al. 2015; Insel & Landis 2013). \nThe diagnosis of psychiatric disorders is still relies on \nself-reporting, information gathered from relatives, long-\nterm interviews and scales (Regier et al. 2013). Howev\xad\ner, reasons such as avoiding social stigma, reluctance to \ninterview, and retrospective recall bias may cause the \ndata obtained to be far from objectivity (Yünden 2022, \nLow et al. 2020). Furthermore, the power of the scales \nused in assessment, management and scoring is limited \nand costly due to time consuming, serious training and \nmultiple information requirements (Kobak et al. 2004). \nDespite advancements in neurobiological studies that \nenhance our understanding of the biological foundations \nof psychiatric disorders, they have not yielded sufficient \nbiomarkers to enhance the objectivity of psychiatric \nPsychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499 https://doi.org/10.24869/psyd.2023.489 \x08\nOriginal paper\n© Medicinska naklada – Zagreb, Croatia\nA NEW ARTIFICIAL INTELLIGENCE-BASED \nCLINICAL DECISION SUPPORT SYSTEM FOR \nDIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES \nBASED ON VOICE ANALYSIS\nNeslihan Cansel1, Ömer Faruk Alcin2, Ömer Furkan Yılmaz3, Ali Ari4, \nMustafa Akan5 & İlknur Ucuz6\n1 Assoc. Prof. Dr., Department of Psychiatry, Inonu University, Faculty of Medicine, Malatya, Turkey\n2 Assoc. Prof. Dr., Department of Software Engineering, Inonu University, Faculty of Engineering, Malatya, Turkey\n3 MD, Department of Psychiatry, Yeşilyurt Hasan Çalik Hospital, Malatya, Turkey\n4 Assist. Prof. Dr., Department of Computer Engineering, Inonu University, Faculty of Engineering, Malatya, Turkey\n5 Assist. Prof. Dr., Department of Psychiatry, Turgut Özal University, Faculty of Medicine, Malatya, Turkey\n6 Assoc. Prof. Dr., Department of Child and Adolescent Psychiatry, Inonu University Faculty of Medicine Malatya, Turkey\nreceived: 19. 04. 2023;\u2003 \u2003 \u2003 \u2003 revised: 24. 05. 2023;\u2003 \u2003 \u2003 \u2003 accepted: 31. 08. 2023\nSummary\n\t\nBackground: Speech features are essential components of psychiatric examinations, serving as important markers in the rec\xad\nognition and monitoring of mental illnesses. This study aims to develop a new clinical decision support system based on artificial \nintelligence, utilizing speech signals to distinguish between bipolar, depressive, anxiety and schizophrenia spectrum disorders.\n\t\nSubjects and methods: A total of 79 patients, who were admitted to the psychiatry clinic between 2020-2021, including 15 \nwith schizophrenia spectrum disorders, 24 with anxiety disorders, 25 with depressive disorders, and 15 with bipolar affective disorder, \nalongside with 25 healthy individuals were included in the study. The speech signal dataset was created by recording participants’ \nreadings of two texts determined by the Russell emotion model. The number of speech samples was increased by using random sam\xad\npling in speech signals. The sample audio signals were decomposed into time-frequency coefficients using Wavelet Packet Transform \n(WPT). Feature extraction was performed using each coefficient obtained from both Mel-Frequency Cepstral Coefficients (MFCC) and \nGammatone Cepstral Coefficient (GTCC) methods. The disorder classification was carried out using k-Nearest Neighbor (kNN) and \nSupport Vector Machine (SVM) classifiers. \n\t\nResults: The success rate of the developed model in distinguishing the disorders was 96.943%. While the kNN model exhibited \nthe highest performance in diagnosing bipolar disorder, it performed the least effectively in detecting depressive disorders. Whereas, \nthe SVM model demonstrated close and high performance in detecting anxiety and psychosis, but its performance was low in identify\xad\ning bipolar disorder.\nThe findings support the utilization of speech analysis for distinguishing major psychiatric disorders. In this regard, the future develop\xad\nment of artificial intelligence-based systems has the potential to enhance the psychiatric diagnosis process.\nKeywords: Artificial intelligence, mental illness, psychiatry, speech signal, Russel emotion model.\n* * * * *\n\n490\nassessment (Insel & Landis 2013). Consequently, there \nis a need for new approaches. In this regard, significant \nadvancements in computer technology have revolution\xad\nized the field of psychiatry, similar to other medical disci\xad\nplines, by enabling the detection of disorder-specific fea\xad\ntures and facilitating the prediction of treatment response \nand prognosis (Siena et al. 2020, van der Sluis et al. 2011, \nMarmar et al. 2019, Hoque et al. 2009, Bzdok D & Mey\xad\ner-Lindenberg A 2018).\nSpeech is a parameter that is frequently examined \nin this field. The reasons for this preference could be at\xad\ntributed to its advantages such as containing numerous \nclinical clues, difficulty in concealing verbal and non-ver\xad\nbal features of the person during speaking, direct expres\xad\nsion of emotions and thoughts through language, and in\xad\ndirect reflection of neuromuscular modulation. Economic \nfactors, availability, and low cost are also among the mo\xad\ntivations for this preference (Bedi et al. 2015; Low et al. \n2020, Yünden 2022).\nIn recent years, a significant number of studies have \ndemonstrated that speech patterns and features collect\xad\ned through mobile devices and sensors can serve as \nbiomarkers for early diagnosis and monitoring of men\xad\ntal disorders (van der Sluis et al. 2011, Cannizzaro et al. \n2004, Pan et al. 2019, Hashim et al. 2017, Karam et al. \n2014, Marmar et al. 2019, Hoque et al. 2009, de Boer \net al. 2020, Siena et al. 2020). For instance, Hashim et \nal. suggested that changes in speech signals consisting \nof acoustic features which characterize specific spectral \nand timing properties can be used in monitoring severity \nof depressive symptoms and treatment response (Hashim \net al. 2017). Faurholt-Jepsen et al. analyzed smartphone \nand self-monitored data over a period of 12 weeks, \ndemonstrating the importance of voice in distinguishing \naffective fluctuations, depression, and manic symptoms \n(Faurholt-Jepsen et al. 2016). Mota et al successfully \nmeasured dysfunctional thought flow such as divergence \nand recurrence in the speech of a group of psychotic pa\xad\ntients can be objectively measured by speech graph anal\xad\nysis (Mota et al. 2012). \nThe fact that most of the studies are based on a single \ndisease group may lead to a decrease in the general use \nof the obtained objective markers and consequently limit \ntheir reliability. To the best of our knowledge, there is no \nexisting study in the literature that distinguishes between \nthe main psychiatric disorder groups using voice analysis.\nTherefore, in this study, it is aimed to develop an arti\xad\nficial intelligence-based clinical decision support system \n(CDSS) with high accuracy, sensitivity, specificity by \nusing speech analysis which distinguishes patients with \nfour main psychiatric disorders including schizophrenia \nspectrum, depressive, and bipolar affective disorders and \nhealthy individuals. \nSUBJECTS AND METHODS\nThis is a cross-sectional study that received prior ap\xad\nproval from the local ethics committee (2020/25). The \nstudy included patients who admitted to the psychiatry \noutpatient clinic of Inonu University Faculty of Medicine \nbetween March 2020 and January 2021 and were diag\xad\nnosed with Anxiety Disorders, Bipolar Disorder, Depres\xad\nsive Disorders, Schizophrenia Spectrum Disorders (SSD) \nand followed up according to DSM-5 diagnostic criteria \n(American Psychiatric Association 2013). Patients eval\xad\nuated by two psychiatrists in accordance with the DSM-\n5 criteria and diagnoses which were confirmed by psy\xad\nchometric scales were invited to the study. Their voices \nwere recorded using an android smartphone (Samsung \nGalaxy S8, Samsung Electronics, 2017, South Korea). \nPsychiatric symptoms were assessed using scales with \nproven validity and reliability in Turkey, including the \nNegative Syndrome Scale (SANS) (Erkoç et al. 1991a) \nand Positive Symptoms Rating Scale (SAPS) for schizo\xad\nphrenia spectrum disorders (Erkoç et al. 1991b), Hamil\xad\nton Anxiety Rating Scale (HAM-A) for anxiety disorders \n(Yazıcı et al. 1998), Hamilton Depression Rating Scale \n(HAM-D) for depressive disorders (Akdemir et al. 1996), \nand Young Mania Rating Scale (YMRS) for bipolar af\xad\nfective disorder (Karadag et al. 2001). Demographic and \nclinical characteristics such as age, gender, marital status, \nduration of psychiatric illness, and use of psychotropic \ndrugs were recorded.\nA control group was selected, matching the patient \ngroups in terms of age, and consisting of individuals who \nwere evaluated by the same psychiatrists. These indi\xad\nviduals underwent a semi-structured interview and were \ndetermined not to meet any psychiatric disorders criteria \naccording to DSM-5. It was ensured that the healthy indi\xad\nviduals had not received treatment for any mental illness\xad\nes previously. Furthermore, participiants with conditions \nor history such as voice impairment or alteration due to \ndiseases (reflux, pharyngitis, etc.) or surgeries, voice or \ndiction training, speech disorders (stuttering, dysarthria), \nneurological diseases, intellectual disability causing cog\xad\nnitive impairment, or inability to speak Turkish were ex\xad\ncluded from the study. Participation was voluntary, and \nwritten consent was obtained.\nDuring the data collection period, the researcher re\xad\nsponsible for the analysis did not have access to the col\xad\nlected data.\nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\n\n491\nData Collection \nData collection involved obtaining voice signals \nfrom the participants reading two texts provided to them. \nThese texts were selected using The Russel Arousal-Va\xad\nlence emotion model in order to minimize any possible \nemotional impact (Figure 1). The model involves pre\xad\nsenting a stimulus to the subjects first and followed by \nan self-evaluation of the emotion created by this stimulus \nwith the Self-Assessment Manikin Questionnaire (SAM) \n(Russell 2003, Alakus et al. 2020). According to SAM, \ntexts corresponding to zone 4th (relaxed, peaceful, calm) \nwere considered neutral stimulus. Initially, 10 texts were \nchosen, and each text was read by the researchers. Two \ntexts that corresponded to the 4th region were selected for \nthe study (Figure 1).\nThe 2 texts determined using this method are as fol\xad\nlows:\nText 1. \x07“BUTTERFLY VALLEY: Fethiye is a paradise \ngarden that can be accessed from the Dead Sea \n(Blue Lagoon) by boats. It brings many people to\xad\ngether and has a unique magic. It is also famous \nfor its waterfalls and the tiger-patterned butter\xad\nflies found only in this region. “\nText 2. \x07“THE DECLARATION OF REPUBLIC: With \nthe acceptance of the constitutional amendment \nproposal prepared by Mustafa Kemal at Turkey’s \nGrand National Assembly in its second period, 29 \nOctober 1923, it is determined that the form of \ngovernment in Turkey is a republic.\nSpeech Signals Analyze and \nClassification Methods\nSpeech signals possess a complex structure that con\xad\ntains valuable information. However, in order to utilize \nthese signals, they must undergo a series of preprocess\xad\ning steps, such as enhancing signal quality, emphasizing \nrelevant components, suppressing external noises, and \ndetermining appropriate sampling values. Following this \npreprocessing stage, the next step is to extract features \nfrom the speech signals. Feature extraction involves \nidentifying characteristic values that describe the speak\xad\ners and can be used for subsequent recognition. The fea\xad\ntures extracted from the audio signals can be classified \ninto acoustic, linguistic, contextual, and hybrid features, \nwhich combine different sets of features. Acoustic fea\xad\ntures are often preferred in studies as they provide more \nobjective insights into sound production and signal struc\xad\nture. Commonly used acoustic features include intona\xad\ntion, formant frequencies, speech rate, sound quality, and \nfeatures based on Mel-Frequency Cepstral Coefficients \n(MFCC) (Özseven 2019, Eskidere & Ertaş 2009). \nIn this study, the speech signals also underwent a se\xad\nries of preprocessing steps, including screening and de\xad\ntermination of sampling values. Subsequently, they were \ntransformed into the time-frequency domain using the \nWavelet Packet Transform (WPT) process. The speech \nfeatures within the transformed signals were computed \nusing the MFCC and Gammatone Cepstral Coefficient \n(GTCC) methods. To classify the extracted features ac\xad\ncording to disease groups, Support Vector Machines \n(SVM) and k-Nearest Neighbor (kNN) methods were \nemployed. The following sections provide a brief expla\xad\nnation of these methods.\nWavelet Packet Transform \nThe wavelet transform is a useful tool for the short-\ntime analysis of speech signals, particularly those that are \nquasi-stationary. The key aspect of the wavelet transform \nis to analyze a signal considering scale. This scaling ap\xad\nproach enables both locality and spectral analysis, pro\xad\nviding a time-frequency representation. There are various \ntype of wavelet transforms such as discrete wavelet trans\xad\nform and WPT. Discrete wavelet transform is suitable for \nanalyzing low-frequency signals, yet it exhibits relatively \nlow resolution in the high frequency region. On the other \nhand, WPT can analyze a signal containing low, mid, and \nhigh-frequency components similarly to the speech sig\xad\nnals (Burrus et al. 1998, Gao & Yan 2011). This feature \nmade WPT to commonly used for detecting and distin\xad\nguishing transients with high frequency characteristics.\nFigure 1. Russel Arousal-Valence emotion model\nAnnoying\nAngry\nNervous\nSad\nBored\nSleepy\nCalm\nPeaceful\nRelaxed\nValence\nPleased\nHappy\nExcited\nArousal\n(high)\n(negative)\n(positive)\n(low)\n2\n3\n1\n4\nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\n\n492\nMel Frequencies Cepstral Coefficient \nMel Frequencies Cepstral Coefficient is a method \nused to detect and characterize speech-specific attributes \nin speaker verification systems. MFCC is a representation \nof the short-term power spectrum of a sound, based on a \nlinear cosine transform of a log power spectrum on a non\xad\nlinear Mel scale of frequency. By dividing the speech into \nsmall frames based on the number of input rows, window \nlength, and overlap length, MFCC computes cepstral fea\xad\ntures for each frame. One of the most significant features \nof MFCC is its ability to mimic the frequency selectivity \nof the human ear, enabling the extraction of distinctive \nand highly performant values (Hossan et al. 2010, Dim\xad\nitrov 2005).\nGammatone Cepstral Coefficient\nGammatone Cepstral Coefficients (GTCC) are a fea\xad\nture extraction technique widely used in speech and audio \nsignal processing. Although, GTCC feature extraction is \nsimilar to MFCC, the Gammatone Cepstral Coefficient \n(GTCC) adopts a frequency scale that has been ana\xad\nlytically devised, showcasing a more refined behavior \ncompared to the Mel-scale. The impulse response of the \nGammatone filter is derived from a combination of the \nGamma distribution function and a sinusoidal tone with a \nspecific frequency positioned at its center. Hence, by uti\xad\nlizing the Gammatone filter, the GTCC not only enhanc\xad\nes the representation of auditory signals but also demon\xad\nstrates the ability to capture the nuances of the human \nauditory system with greater fidelity than MFCC ( Balli \n2022, Valero\xa0&\xa0\xa0Alias 2012),\nk-Nearest Neighbor\nThe k-NN algorithm, a non-parametric learning al\xad\ngorithm, is widely used among machine learning meth\xad\nods due to its simplicity and good performance (Cover \n& Hart 1967). The k-NN method determines the class to \nwhich a new observation belongs by utilizing the obser\xad\nvation values in a sample set with predefined classes. In \nthis algorithm, the distance between the new data and the \nrecognized data is calculated for k points, and the new \ninformation is classified based on this distance (Ozkan \n2016). \nSupport Vector Machines\nSVM is an important and efficient supervised classi\xad\nfication algorithm. The essence of the algorithm is based \non detecting a hyperplane in a high-dimensional space \nthat maximally separates the different classes. When a \nlinearly separable dataset is provided to the system by \nbinary classification, an infinite number of hyperplanes \nare formed that can separate the input set. SVM con\xad\nstructs a decision plane to maximize the distance be\xad\ntween the two classes. This decision plane allows for \nthe classification of objects with different class mem\xad\nberships, and SVM finds the best hyperplane with the \nmaximum margin to separate them (Tekerek 2019, Siuly \net al. 2020). \nStatistical Analysis\nSPSS 22 (Statistical Package for Social Sciences; \nSPSS Inc., Chicago, IL) package program was used to \nanalyze the data of the participants. Among the descrip\xad\ntive data in the study, qualitative variables were shown \nas number and percentage (n and %), and quantitative \nvariables as mean±standard deviation (Mean±SD) values. \nIndependent sample t-test was used to compare the age \ndistribution between the groups. A value of p<0.05 was \nconsidered statistically significant.\nRESULTS\nSociodemographic Features\nOne hundred four participants were included in the \nstudy. Fifteen of the participants had a diagnosis of SSD, \n24 had an anxiety disorder, 25 had major depressive dis\xad\norder, 15 had a diagnosis of bipolar affective disorder. \nThe control group was consisted of 25 healthy individ\xad\nuals. The mean age of the participants was 36.53±13.10 \nyears and there was no statistical difference between the \ngroups (p=0.129). It was found that, the mean SANS to\xad\ntal score was 27.3±21.02 and the mean SAPS score was \n19.46±20 in the SSD patients. The mean HAM-A score \nwas 22.3±9.6 in the anxiety group, the mean HAM-D \nscore was 15.3±5.7 in the depressive group, and the mean \nYMRS total score was 14.5±7.9 in the bipolar group. The \nsociodemographic characteristics of the participants were \ngiven in Table 1.\nDesign of Speech Analysis Clinical \nDecision Support System\nThe proposed method aims to detect bipolar, depres\xad\nsive, anxiety, and schizophrenia spectrum disorders from \nspeech signals. Participants were instructed to read the \ntwo texts mentioned above once. Recordings were exclud\xad\ned from the analysis if there was unwanted background \nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\n\n493\nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\nTable 1. Sociodemographic and clinical features of the participants\nVariable\nSSD group\nAnxiety \ngroup\nDepressive \ngroup\nBipolar \ngroup\nHealthy \ncontrols\nAge (mean±SD)\n36.5±13.1\n35.2±11.3\n37.5±11.0\n35.6±11.0\n29.8±8.1\nPsychiatric onset age (mean±SD)\n24.3±6.9\n30.4±9.6\n30.9±10.1\n24.3±7.2\n-\nn (%) \nGender \nFemale\nMale\n6 (40)\n9 (60)\n20 (83.3)\n4 (16.7)\n22 (88)\n3 (12)\n13 (86.7)\n2 (13.3)\n17 (68)\n8 (32)\nPlace of birth Province\nDistrict\nVillage\n11 (73.3)\n3 (20)\n1 (6.7)\n18 (75)\n5 (20.8)\n1 (4.2)\n14 (56)\n7 (28)\n4 (16)\n8 (53.3)\n6 (40)\n1 (6.7)\n20 (80)\n3 (12)\n2 (8)\nEducation \nlevel\nPrimary \nHigh school\nUniversity\n4 (26.7)\n6 (40)\n5 (33.3)\n7 (29.2)\n8 (33.3)\n9 (37.5)\n13 (52)\n4 (16)\n8 (32)\n5 (33.3)\n5 (33.3)\n5 (33.3)\n0\n5 (20)\n20 (80)\nProfession \nUnemployed \nWorker\nOfficer\nOther\n10 (66.7)\n0\n5 (33.3)\n0\n17 (70.8)\n1 (4.2)\n4 (16.7)\n2 (8.3)\n19 (76)\n4 (16)\n2 (8)\n0\n11 (73.3)\n1 (6.7)\n2 (13.3)\n1 (6.7)\n12 (48)\n3 (12)\n10 (40)\n0\nMarital status Single\nMarried \nWidow/Divorced\n11 (73.3)\n3 (20)\n1 (6.7)\n7 (29.2)\n15 (62.5)\n2 (8.3)\n6 (24)\n18 (72)\n1 (4)\n5 (33.3)\n7 (46.7)\n3 (20)\n14 (56)\n11 (44)\n0\nEconomic \nLevel \n0-2000\n2000-5000\n>5000\n8 (53.3)\n1 (6.7)\n6 (40)\n10 (41.7)\n0\n14 (58.3)\n16 (64)\n2 (8)\n7 (28)\n12 (80)\n0\n3 (20)\n11 (44)\n0\n14 (56)\nLiving place \nProvince\nDistrict\nVillage\n15 (100)\n0\n0\n21 (87.5)\n1 (4.2)\n2 (8.3)\n23 (92)\n1 (4)\n1 (4)\n10 (66.7)\n3 (20)\n2 (13.3)\n20 (80)\n3 (12)\n2 (8)\nChronic \ninternal \ndisease history \nNo\nYes\n13 (86.7)\n2 (13.3)\n16 (66.7)\n8 (33.3)\n22 (88)\n3 (12)\n14 (93.3)\n1 (6.7)\n20 (80)\n5 (20)\nAlcohol-\n‑substance use \nhistory \nNo\nYes\n14 (93.3)\n1 (6.7)\n23 (95.8)\n1 (4.2)\n25 (100)\n0\n13 (86.7)\n2 (13.3)\n25 (100)\n0\nHistory of \nsmoking \nNo\nYes\n9 (60)\n6 (40)\n16 (66.7)\n8 (33.3)\n15 (60)\n10 (40)\n9 (60)\n6 (40)\n 22 (88)\n3 (12)\nCurrent \ncomplaints \nstart time\n> 1 month\n1-6 months\n6 months-1 year\n> 1 year\nRemission\n2 (13.3)\n1 (6.7)\n4 (26.7)\n5 (33.3)\n3 (20)\n4 (16.7)\n11 (45.8)\n2 (8.3)\n7 (29.2)\n0\n0\n9 (36)\n7 (28)\n9 (36)\n0\n3 (20)\n8 (53.3)\n2 (13.3)\n2 (13.3)\n0\n-\nDrug \ncurrently used \nNone\nOnly AP\nOnly SRI/SNRI\nOnly MSD\nSSRI+AP\nAP+MSD\n1 (6.7)\n12 (80)\n0\n0\n1 (6.7)\n1 (6.7)\n3 (12.5)\n1 (4.2)\n19 (79.2)\n0\n1 (4.2)\n0\n6 (24)\n1 (4)\n13 (52)\n0\n4 (16)\n1 (4)\n0\n1 (6.7)\n0\n3 (20)\n0\n11 (73.3)\n-\nAP: Antipsychotic, SSRI: Selective Serotonin Reuptake Inhibitor; SNRI: Serotonin-Noradrenaline Reuptake inhibitor, MSD: \nMood-Stabilizing Drugs, SSD: Schizophrenia Spectrum Disorders\n\n494\nnoise or if the speech was not clearly understandable. As \na result, a dataset consisting of 193 speech signals was \ncreated, involving 104 participants. The speech signals \nwere recorded at a sampling frequency of 44,100Hz, and \nthe overall speech record, which lasted an average of 30 \nseconds, contained approximately one million samples.\nIn the experiments, the number of speech signals was \nincreased by a random subsampling approach. through \ndata augmentation, 100,000 samples were randomly \nselected from each speech signal, and this process was \nrepeated ten times. Consequently, an augmented data\xad\nset of 1,930 sampled data points was obtained from the \noriginal data. The augmented data set was transformed \ninto time-frequency coefficients using WPT with four \nlevels. Thus, time-frequency coefficients with distinctive \nspeech signal clips were obtained. The parameters of the \nWPT method, including Shannon entropy and the db3 \nwavelet family, were chosen heuristically. Sixteen (2-level) \ntime-frequency coefficients are obtained with four-level \nWPT. Distinctive features were calculated from the WPT \ncoefficients of the speech signals using the MFCC and \nGTCC methods. A 1x28 feature vector, consisting of four\xad\nteen MFCCs and fourteen GTCCs, was formed from each \nWPT coefficient Considering all the WPT coefficients, a \n1,930x448-dimensional feature vector was ultimately ob\xad\ntained. Subsequently, k-NN and SVM classifiers were \nemployed to detect disorders based on the obtained fea\xad\ntures. For kNN, the parameters were determined exper\xad\nimentally, taking into account the lowest error rate, the \nEuclidean distance metric, and k=3.\nThe linear kernel in SVM kernel functions are used \nbecause of providing the best results compared to oth\xad\ner kernel functions. All experiments were carried out in \nMATLAB environment on a computer equipped with a \n2.70 GHz CPU processor and 32 GB RAM. The algo\xad\nrithm of the proposed method were given in Figure 2.\nExperimental Results\nTo evaluate the performance of the proposed method, \naccuracy (Acc.), sensitivity (Sens.), specificity (Spec.), \nprecision (Prec.), F1-score, MCC, and kappa metrics, \nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\nFigure 2. The proposed framework for detection psychiatric disorders from speech signal\nSpeech Signals \nRandom Subsampling\nClassification \nSVM & KNN\nFeature Extraction\nMFCC & GTCC\nWavelet Packet Transform\n\n495\nwhich are widely used in biomedical applications were \nused. Five-fold cross-validation was used to validate the \nproposed method. Accuracy represents the ability to give \nthe same value during repeated measurements of phys\xad\nical size. Sensitivity indicates the ability of a classifica\xad\ntion model to correctly identify positive instances from \nall the actual positive instances. Conversely, specificity \nrefers to the ability of a model to find actual healthy indi\xad\nviduals among undiagnosed individuals. Precision is the \nproportion of correctly predicted positive instances out \nof all instances predicted as positive. F1-score value is \nthe harmonic mean of precision and recall values. Kappa \nparameter indicates the agreement between observed and \nexpected values and ranges from -1 to +1. A high kappa \nvalue implies that the evaluated model is performing well \nand shows a strong agreement with the reference. Hence\xad\nforward, kappa values close to 1 were used for our model. \nThe performance parameters of the SVM classifier \nwere calculated as 96.477% accuracy, 96.051% sensitiv\xad\nity, 99.110% specificity, 96.338% precision, F1 score of \n0.962, MCC value of 0.953, and kappa value of 0.890. The \nperformance parameters of the kNN classifier were calcu\xad\nlated as 96.943% accuracy, 96.930% sensitivity, 99.228% \nspecificity, 96.802% precision, F1 score of 0.969, MCC \nvalue of 0.961 and kappa value of 0.904. These results of \nthe proposed system are showed in Table 2.\nAlthough the performance parameters of the two clas\xad\nsifiers seem to be close to each other, kNN performed \nslightly better than SVM. Experimental analysis was pro\xad\nceeded by drawing the Receiver Operating Characteristic \n(ROC) curves. The ROC curve helps to evaluate the over\xad\nall classifier performance. The ROC curves were shown \nin Figure 3 for the kNN, and in Figure 4 for the SVM \nclassifier.\nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\nTable 2. Performance results of the proposed methods\nMethod\nAcc. (%)\nSens. (%)\nSpec. (%) Prec.(%)\nF1-score\nMCC\nKappa\nSVM\n 96.477 \n 96.051 \n 99.110 \n 96.338\n 0.962\n 0.953\n 0.890\nkNN\n 96.943 \n 96.930 \n 99.228 \n 96.802\n 0.969\n 0.961\n 0.904\nFigure 3. ROC curve for \nkNN classifier \nFalse Positive Rate\n0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nTrue Positive Rate\nROC curve for kNN\nAnxiety\nBipolar\nDepression\nControl\nPsychosis\n\n496\nWhen examining the ROC curve in Figure 3, kNN \nwas the most successful method in distinguishing the \ncontrol group from the patient group. However, the kNN \nmodel performed lower than other methods in detecting \ndepression. On the other hand, the SVM model distin\xad\nguishes the control group better, as well as the kNN mod\xad\nel. While SVM showed a close performance resemblance \nin detecting anxiety and psychosis, it displayed lower \nperformance in bipolar detection (Figure 4).\nDISCUSSION\nIn this study, an artificial intelligence-based clinical \ndecision support system was developed with a perfor\xad\nmance of 96.943% to detect bipolar disorder, depres\xad\nsive, anxiety, and schizophrenia spectrum disorders from \nsound signals and distinguish them from the healthy con\xad\ntrol group.\nVarious studies in the literature have shown that voice \nanalysis can be used for clinical classification in differ\xad\nent patient groups. For example, Tahir et al. classified \nschizophrenia patients and healthy controls with 81.3% \naccuracy using non-verbal language measures (Tahir et \nal. 2019). Martínez-Sánchez et al., were able to distin\xad\nguish schizophrenic patients from healthy controls with \nover 90% sensitivity, specificity and overall accuracy, \nthanks to the method they developed using the prosodic \nand phonetic sound features determined while reading a \ntext (Martínez-Sánchez et al. 2015). By examining the \nsounds obtained from patients’ videotapes, Cannizzaro \net al. obtained data indicating that motor timing param\xad\neters reflecting speech production (for example, speech \nrate and pause time) and frequency modulation (for ex\xad\nample, pitch variability) were significantly associated \nwith the severity of depression (Cannizzaro et al. 2004). \nSimilarly, Maxhuni et al. in their study followed bipolar \npatients with a smartphone-based system and classified \ntheir mood transitions at a rate higher than 80% by us\xad\ning the speech, accelerometer and self-assessment-relat\xad\ned data obtained from daily phone calls (Maxhuni et al. \n2016).\nIn our study, unlike these studies that focused on a \nsingle disorder sample, we created a CDSS that covers \nfour main disorders groups and obtained 448 different \nfeatures from the audio signals to develop this system. \nThis allowed for more sophisticated separations and \npromising clinical use of the model. It should be noted \nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\nFalse Positive Rate\n0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nTrue Positive Rate\nROC curve for SVM\nAnxiety\nBipolar\nDepression\nControl\nPsychosis\nFigure 4. ROC curve for \nSVM classifier\n\n497\nthat most previous studies used data from daily conversa\xad\ntions and interviews, which could involve possible emo\xad\ntional manipulations. In our study, we provided a neu\xad\ntral stimulus using the Russell Arousal-Valence emotion \nmodel, resulting in a more objective dataset. With ran\xad\ndom sampling, the number of samples was increased, so \nthat the developed artificial-intelligence model learned \nfrom more samples and its classification performance \nwas increased (Jiao et al. 2018, Aggarwal 2019). By de\xad\ncomposing the augmented dataset into four levels using \nWPT and extracting distinctive features using MFCC and \nGTCC methods, we developed a method with a success \nrate of 96.943%. This result indicated a considerably \nhigher performance compared to studies that partially \nincluded a small number of patients, mostly used only \none type of data, and did not consider more than two dis\xad\norders at the same time. Furthermore, we tested existing \nclassifiers and determined which disorders the machine \nlearning models were more specific for. As an illustra\xad\ntion, the kNN model exhibited superior performance \nin identifying bipolar disorder, but it demonstrated the \nleast effective performance in detecting depression. On \nthe other hand, the SVM model demonstrated a strong \nand comparable performance in distinguishing between \nanxiety and SSD, although its performance in detecting \nbipolar disorders was comparatively lower than that of \nthe other groups.\nWhile this study contributes valuable insights, it is \nimportant to address certain limitations that should be \ntaken into consideration. First, participation in the re\xad\nsearch was dependent on voluntary, and as a result, the \nsample size remained relatively low. Additionally, all \nof the participants resided in the same region and had \nsimilar cultural and linguistic characteristics. Therefore, \nalthough the developed method has shown an effective \nperformance for this data set, it is unknown whether \nthe obtained results can be generalized to a new sample \nwith different ages, geography, socioeconomic levels, \nand registration types. Second, the small sample size \nprevented the differentiation of variables that could im\xad\npact the voice structure, such as gender (length of vocal \ncords and speech patterns, as well as acoustic charac\xad\nteristics like duration, intensity, and frequency of voice \nand speech signals, which may differ between genders), \nsmoking (which can change the acoustic properties of \nthe voice by causing histological changes on the vocal \nfold epithelium), and the type of psychotropic treatment \n(which may cause impairment in speech-related motor \nfunctions). Third, subgroups (delusional disorder, schi\xad\nzoaffective disorder, obsessive compulsive disorder, \nphobias, panic disorder, dysthymia etc) were not ana\xad\nlyzed, and patient groups were grouped based on the core \nsymptoms. Consequently, it remains unclear whether the \nmodel would be effective in distinguishing subgroups. \nFourth, although neuropsychological deficiencies that \nmay affect acoustic or lexical expression were assessed \nbased on history, neuropsychological tests were not em\xad\nployed to detect these conditions. Finally, considering \nthe depth and obscurity of the human psyche, it may not \nbe ethically appropriate to rely solely on sound features \nfor a “definitive” diagnosis. In the future, multicenter \nstudies that would be conducted in large populations and \nthat evaluate more markers together could provide more \nreliable results. \nDespite all these limitations, our study is the first to \nutilize machine learning methods distinguishing four dif\xad\nferent main psychiatric disorders and healthy person and \nmay lead to future studies. Considering the performance \nparameters, the developed method can be employed by \nexperts as an effective and reliable tool to assist in di\xad\nagnosing mental illnesses, thereby contributing to effi\xad\nciency in terms of speed and time. The CDSS may be \nbeneficial for patients to be evaluated more objectively, \nindependent of factors such as the evaluator’s experience, \nattention, and mood, as well as the partially low-reliabil\xad\nity of self-report measures. Furthermore, it can also be \napplied to assess specific populations, such as children or \nthe elderly, who may encounter difficulties in expressing \nthemselves. Additionally, it can be employed for monitor\xad\ning patients undergoing extreme circumstances, such as \ndisasters, wars, or pandemics, where regular check-ups \nmay be hindered. \nCONCLUSION\nIn this study, a new artificial intelligence-based meth\xad\nod was presented, which achieves a performance param\xad\neter above 96.943% and can automatically and accurately \nclassify psychiatric disorders from healthy controls. The \nkNN model demonstrated high performance, particular\xad\nly in diagnosing bipolar disorder, while the SVM model \nshowed comparable high performance in distinguishing \nanxiety and SSD. The developed method holds the poten\xad\ntial to assist psychiatrists in efficiently and reliably distin\xad\nguishing their patients. \nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\n\n498\nAcknowledgements: None.\nEthical Considerations: Does this study include \nhuman subjects? YES\nAuthors confirmed the compliance with all relevant ethi\xad\ncal regulations.\nConflict of interest: No conflict of interest\nFunding sources: The authors received no funding \nfrom an external source.\nAuthors contributions: Neslihan cansel & İlknur \nUcuz: study design, statistical analysis, first draft. Ömer \nFurkan Yılmaz & Mustafa Akan: data collection. Ömer \nFaruk Alçin & Ali Arı: data analysis and development of \nclinic support system. All authors approval of the final \nversion.\nReferences\n1.\t Aggarwal SLP: Data augmentation in dermatology image \nrecognition using machine learning. Skin Research and \nTechnology 2019; 25: 815-820.\n2.\t Akdemir A, Örsel DS, Dağ İ, Türkçapar MH, İşcan N, Öz\xad\nbay H: Hamilton depresyon derecelendirme ölçeği (HD\xad\nDÖ)’nin geçerliliği-güvenirliliği ve klinikte kullanımı. Psi\xad\nkiyatri Psikoloji Psikofarmakoloji Dergisi 1996; 4: 251-259.\n3.\t Alakus TB, Gonen M, Turkoglu I: Database for an emotion \nrecognition system based on EEG signals and various com\xad\nputer games–GAMEEMO. Biomed Signal Process Control \n2020; 60: 101951.\n4.\t American Psychiatric Association: Diagnostic and Statisti\xad\ncal Manual of Mental Disorders 5. Washington, D.C., 2013.\n5.\t Balli O: Vücut Seslerinden Bölge Tanımlanması için İdeal \nKayıt Süresinin Belirlenmesinde MFCC ve GTCC Öznite\xad\nliklerinin Etkisinin Karşılaştırılması.” Avrupa Bilim ve Te\xad\nknoloji Dergisi 2022;43:36-40.\n6.\t Bedi G, Carrillo F, Cecchi GA, Slezak DF, Sigman M, Mota \nNB, et al.: Automated analysis of free speech predicts psy\xad\nchosis onset in high-risk youths. NPJ Schizophr 2015; 1: \n15030.\n7.\t Burrus CS, Gopinath RA, Guo H: Introduction to Wavelets \nand Wavelet Transforms, A Primer. Upper Saddle River, Nj, \nPrentice-Hall, 1998.\n8.\t Bzdok D & Meyer-Lindenberg A: Machine Learning for \nPrecision Psychiatry: Opportunities and Challenges. Biol \nPsychiatry Cogn Neurosci Neuroimaging 2018; 3: 223-230.\n9.\t Cannizzaro M, Harel B, Reilly N, Chappell P, Snyder PJ: \nVoice acoustical measurement of the severity of major de\xad\npression. Brain Cogn 2004; 56: 30-35.\n10.\t Cover T & Hart P: Nearest neighbor pattern classification. \nIEEE transactions on information theory 1967; 13: 21-27.\n11.\t de Boer JN, Brederoo SG, Voppel AE, Sommer IEC: Anom\xad\nalies in language as a biomarker for schizophrenia. Curr \nOpin Psychiatry 2020; 33: 212-218.\n12.\t Dimitrov Ganchev T: Speaker recognition. Unpublished \ndoctoral dissertation. Dept of Electrical and Computer En\xad\ngineering, University of Patras, Greece, 2005.\n13.\t Erkoç S, Arkonaç O, Ataklı C, Özmen E: Pozitif Semptom\xad\nları Değerlendirme Ölçeğinin güvenilirliğini ve geçerliliği. \nDüşünen Adam Dergisi, 1991a; 4: 20-24.\n14.\t Erkoç S, Arkonaç O, Ataklı C, Özmen E: Negatif Semptom\xad\nları Değerlendirme Ölçeğinin güvenilirliğini ve geçerliliği. \nDüşünen Adam Dergisi, 1991b; 4: 14-15.\n15.\t Eskidere Ö & Ertaş F: MEL Frekansı Kepstrum Kat\xad\nsayılarındaki Değişimlerin Konuşmacı Tanımaya Etkisi. \nUludağ Üniversitesi Mühendislik Fakültesi Dergisi. 2009; \n14(2): 93-110\n16.\t Faurholt-Jepsen M, Busk J, Frost M, Vinberg M, Chris\xad\ntensen EM, Winther O, et al: Voice analysis as an objective \nstate marker in bipolar disorder.\xa0Translational Psychiatry, \n2016; 6(7): e856 \n17.\t Gao, R.X., Yan, R. (2011). Wavelet Packet Trans\xad\nform. In: Wavelets. Springer, Boston, MA. https://doi.\norg/10.1007/978-1-4419-1545-0_5\n18.\t Hashim NW, Wilkes M, Salomon R, Meggs J, France DJ: \nEvaluation of Voice Acoustics as Predictors of Clinical De\xad\npression Scores. J Voice 2017; 31: 256.e1-256.e6.\n19.\t Hoque ME, Lane JK, El Kaliouby R, Goodwin M, Picard \nRW: Exploring speech therapy games with children on the \nautism spectrum. Proc Annu Conf Int Speech Commun As\xad\nsoc, INTERSPEECH, 2009.\n20.\tHossan MA, Memon S, Gregory MA: A novel approach for \nMFCC feature extraction. 4th Int Conf Signal Process Com\xad\nmun Syst IEEE, 2010; 1-5.\n21.\tInsel TR & Landis SC: Twenty-five years of progress: the \nview from NIMH and NINDS. Neuron 2013; 80: 561-567.\n22.\tJarman L, Martin A, Venn A, Otahal P, Blizzard L, Teale B \n& Sanderson K: Workplace Health Promotion and Mental \nHealth: Three-Year Findings from Partnering Healthy@\nWork. PloS 2016;1(8):e0156791. \n23.\tJiao Y, Tu M, Berisha V, Liss J: Simulating dysarthric \nspeech for training data augmentation in clinical speech \napplications. In IEEE international conference on acoustics, \nspeech and signal processing (ICASSP) 2018; 6009-6013.\n24.\tKaradağ F, Oral ET, Aran Yalçın F, Erten E: Young mani \nderecelendirme ölçeğinin Türkiye’de geçerlik ve güvenil\xad\nirliği. Türk Psikiyatri Dergisi 2001; 13: 107-14.\n25.\tKaram ZN, Provost EM, Singh S, Montgomery J, Archer \nC, Harrington G, et al.: Ecologically valid long-term mood \nmonitoring of individuals with bipolar disorder using \nspeech. Proc IEEE Int Conf Acoust Speech Signal Process \n2014; 2014: 4858-4862.\n26.\tKobak KA, Engelhardt N, Williams JB, Lipsitz JD: Rater \ntraining in multicenter clinical trials: issues and recom\xad\nmendations. J Clin Psychopharmacol 2004; 24: 113-117.\n27.\t Low DM, Bentley KH & Ghosh SS: Automated assessment of \npsychiatric disorders using speech: A systematic review. La\xad\nryngoscope Investigative Otolaryngology 2020: 5(1); 96–116\nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\n\n499\n28.\tMarmar CR, Brown AD, Qian M, Laska E, Siegel C, Li M, \net al.: Speech-based markers for posttraumatic stress disor\xad\nder in US veterans. Depress Anxiety 2019; 36: 607-616.\n29.\t Martínez-Sánchez F, Muela-Martínez JA, Cortés-Soto P, \nGarcía Meilán JJ os., Vera Ferrándiz JA ntoni., Egea Capar\xad\nrós A, et al.: Can the Acoustic Analysis of Expressive Prosody \nDiscriminate Schizophrenia? Span J Psychol 2015; 18: E86.\n30.\tMaxhuni A, Muñoz-Meléndez A, Osmani V, Perez H, May\xad\nora O, Morales EF: Classification of bipolar disorder epi\xad\nsodes based on analysis of voice and motor activity of pa\xad\ntients. Pervasive Mob Comput 2016; 31: 50-66.\n31.\tMota NB, Vasconcelos NA, Lemos N, Pieretti AC, Kinou\xad\nchi O, Cecchi GA et al.: Speech graphs provide a quan\xad\ntitative measure of thought disorder in psychosis. PLoS \n2012;7(4):e34928. \n32.\t Ozkan H: A comparison of classification methods for telediag\xad\nnosis of Parkinson’s disease. Entropy 2016:18(4);(2016):115\n33.\tÖzseven T: Konuşma Tabanlı Duygu Tanımada Ön İşleme \nve Öznitelik Seçim Yöntemlerinin Etkisi. Dicle Üniversite\xad\nsi Mühendislik Fakültesi Mühendislik Dergisi 2019; 10(1): \n99-112\n34.\tPan W, Flint J, Shenhav L, Liu T, Liu M, Hu B, et al.: Re-ex\xad\namining the robustness of voice features in predicting de\xad\npression: Compared with baseline of confounders. PLoS \nOne 2019; 14: e0218172.\n35.\tRegier DA, Narrow WE, Clarke DE, Kraemer HC, Kura\xad\nmoto SJ, Kuhl EA, et al.: DSM-5 field trials in the United \nStates and Canada, Part II: test-retest reliability of selected \ncategorical diagnoses. Am J Psychiatry 2013; 170: 59-70.\n36.\tRussell JA: Core affect and the psychological construction \nof emotion. Psychol Rev 2003; 110: 145-172.\n37.\tSiena FL, Vernon M, Watts P, Byrom B, Crundall D, Bree\xad\ndon P: Proof-of-Concept Study: a Mobile Application to \nDerive Clinical Outcome Measures from Expression and \nSpeech for Mental Health Status Evaluation. J Med Syst \n2020; 44: 209.\n38.\tSiuly S, Alcin OF, Kabir E, Sengur A, Wang H, Zhang Y, et \nal.: A New Framework for Automatic Detection of Patients \nWith Mild Cognitive Impairment Using Resting-State EEG \nSignals. IEEE Trans Neural Syst Rehabil Eng 2020; 28: \n1966-1976.\n39.\tTahir Y, Yang Z, Chakraborty D, Thalmann N, Thalmann D, \nManiam Y, et al.: Non-verbal speech cues as objective mea\xad\nsures for negative symptoms in patients with schizophrenia. \nPLoS One 2019; 14: e0214314.\n40.\t Tekerek A: Support Vector Machine Based Spam SMS De\xad\ntection. Politeknik Dergisi 2019;22 (3):779-784\n41.\t Valero X & Alias F: Gammatone Cepstral Coefficients: Bi\xad\nologically Inspired Features for Non-Speech Audio Classi\xad\nfication,” in IEEE Transactions on Multimedia. IEEE trans\xad\nactions on multimedia 2012; 14(6): 1684-1689.\n42.\t van der Sluis F, van den Broek E, Dijkstra T: Towards an \nartificial therapy assistant: Measuring excessive stress from \nspeech. In Traver V, Fred A, Filipe J, Gamboa H (eds): Pro\xad\nceedings of the International Conference on Health Informat\xad\nics, HealthInf, 357-363. INSTICC PRESS, Portugal, 2011. \n43.\t WHO:Mental Disorders. Available from: https://www.who.int/\nnews-room/fact-sheets/detail/mental-disorders. (accessed Ju\xad\nne 15, 2023)\n44.\t Yazıcı MK, Demir B, Tanrıverdi N, Karaoğlu E, Yolaç P: \nHamilton Anksiyete Değerlendirme Ölçeği, Değerlendir\xad\niciler Arası Güvenirlik ve Geçerlik Çalışması. Türk Psiki\xad\nyatr Derg 1998; 9: 114- 117.\n45.\t Young RC, Biggs JT, Ziegler VE, Meyer DA: A rating scale \nfor mania: Reliability, validity and sensitivity. Br J Psychia\xad\ntry 1978; 133: 429-435.\n46.\t Yünden S: Psikiyatrik Hastalıklarda Ses Analizi. Cur\xad\nrent Research and Reviews in Psychology and Psychiatry \n2022:2(2);201-216\nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\nCorrespondence:\nİlknur Ucuz\nAssoc. Prof. Dr., \nDepartment of Child and Adolescent Psychiatry, \nInonu University Faculty of Medicine Malatya, Turkey, \nilknur_27@yahoo.com, +00905072383095, \nORCID id: 0000-0003-1986-4688.'}], 'model': 'academic-extractor', 'max_tokens': 4096, 'response_format': {'type': 'json_object'}}
2026-01-02 12:58:04,317 - instructor - DEBUG - max_retries: 3, timeout: None
2026-01-02 12:58:04,317 - instructor - DEBUG - Retrying, attempt: 1
2026-01-02 12:58:04,322 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-79b82c78-416c-4ab2-8ab4-2533bd8db0ce', 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert academic data extractor.\n\n\n        As a genius expert, your task is to understand the content and provide\n        the parsed objects in json that match the following json_schema:\n\n\n        {\n  "properties": {\n    "title": {\n      "description": "What is the complete title of this academic paper? (Hint: The title is usually at the top of the first page in large, bold text. It may span multiple lines.) [Examples: Input: Digital Phenotype for Childhood Internalizing Disorders: Less Positive Play and Promise for a Brief Assessment Battery -> Output: Digital Phenotype for Childhood Internalizing Disorders: Less Positive Play and Promise for a Brief Assessment Battery]",\n      "title": "Title",\n      "type": "string"\n    },\n    "authors": {\n      "description": "List all authors of this paper in the order they appear, including their full names. (Hint: Authors are typically listed below the title, often with affiliations. Include all authors even if there are many.) [Examples: Input: John Smith, Jane Doe, Robert Johnson -> Output: [\'John Smith\', \'Jane Doe\', \'Robert Johnson\']]",\n      "items": {\n        "type": "string"\n      },\n      "title": "Authors",\n      "type": "array"\n    },\n    "first_author": {\n      "description": "Who is the first author of this paper? (Hint: The first author is typically the lead researcher and appears first in the author list.)",\n      "title": "First Author",\n      "type": "string"\n    },\n    "corresponding_author": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Who is the corresponding author? Look for email addresses or \'Corresponding author\' labels. (Hint: The corresponding author usually has an email address listed or is marked with an asterisk or \'Corresponding author\' notation.)",\n      "title": "Corresponding Author"\n    },\n    "first_author_department": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "What department or institution is the first author affiliated with? (Hint: Look for institutional affiliations listed with the first author\'s name. This is usually found below the author names or in the author information section.) [Examples: Input: Department of Psychology, University of California -> Output: Department of Psychology, University of California]",\n      "title": "First Author Department"\n    },\n    "corresponding_author_department": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "What department or institution is the corresponding author affiliated with? (Hint: Look for institutional affiliations listed with the corresponding author\'s name. This is usually found below the author names or in the author information section.) [Examples: Input: Department of Psychiatry, Harvard Medical School -> Output: Department of Psychiatry, Harvard Medical School]",\n      "title": "Corresponding Author Department"\n    },\n    "research_method": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "What research methodology was used in this study? (Hint: Look for sections labeled \'Methods\', \'Methodology\', or \'Study Design\'. Common methods include experimental, observational, survey, case study, etc.) [Examples: Input: This was a randomized controlled trial -> Output: Randomized controlled trial]",\n      "title": "Research Method"\n    },\n    "sample_size": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "How many participants or subjects were included in this study? (Hint: Look for numbers in the Methods section or Results section. It might be stated as \'N = 100\' or \'100 participants\'.) [Examples: Input: A total of 150 participants were recruited -> Output: 150 participants]",\n      "title": "Sample Size"\n    },\n    "study_population": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Who were the study participants? Describe the population studied. (Hint: Look in the Methods section for participant descriptions, including age, gender, demographics, or specific groups studied.) [Examples: Input: Children aged 8-12 years with internalizing disorders -> Output: Children aged 8-12 years with internalizing disorders]",\n      "title": "Study Population"\n    },\n    "statistical_methods": {\n      "anyOf": [\n        {\n          "items": {\n            "type": "string"\n          },\n          "type": "array"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "What statistical methods or analyses were used in this study? (Hint: Look in the Methods or Results section for statistical tests mentioned, such as t-tests, ANOVA, regression, etc.) [Examples: Input: We used t-tests and ANOVA for group comparisons -> Output: [\'t-tests\', \'ANOVA\']]",\n      "title": "Statistical Methods"\n    },\n    "main_findings": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "What are the main findings or results of this study? (Hint: Look in the Results section or Conclusion section for key findings. Focus on the most important results.) [Examples: Input: The study found significant differences in digital behavior between groups -> Output: Significant differences in digital behavior were found between groups]",\n      "title": "Main Findings"\n    },\n    "limitations": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "What are the main limitations of this study? (Hint: Look in the Results section or Conclusion section for limitations.) [Examples: Input: The study found significant differences in digital behavior between groups -> Output: Significant differences in digital behavior were found between groups]",\n      "title": "Limitations"\n    }\n  },\n  "required": [\n    "title",\n    "authors",\n    "first_author"\n  ],\n  "title": "AcademicPaperExtraction",\n  "type": "object"\n}\n\n        Make sure to return an instance of the JSON, not the schema itself\n'}, {'role': 'user', 'content': 'Extract data from this paper:\n\n489\nINTRODUCTION\nMental illnesses are common illnesses characterized \nby a clinically significant disturbance in an individual’s \ncognition, emotional regulation, or behavior. It has been \nreported that approximately 970 million people world\xad\nwide are currently affected by one or more mental dis\xad\norders, with an expected increase in the future (WHO, \n2022). Psychiatric disorders are predominantly chronic \nand have a substantial impact on the global economy, \nleading to decreased work performance and high treat\xad\nment costs (Jarman et al. 2016). Although these disorders \ncan be treated and symptom improvement is possible with \naccurate diagnosis, the presence of biological and clini\xad\ncal heterogeneity, coupled with the absence of diagnostic \nbiomarkers, makes the diagnostic process challenging \n(Bedi et al. 2015; Insel & Landis 2013). \nThe diagnosis of psychiatric disorders is still relies on \nself-reporting, information gathered from relatives, long-\nterm interviews and scales (Regier et al. 2013). Howev\xad\ner, reasons such as avoiding social stigma, reluctance to \ninterview, and retrospective recall bias may cause the \ndata obtained to be far from objectivity (Yünden 2022, \nLow et al. 2020). Furthermore, the power of the scales \nused in assessment, management and scoring is limited \nand costly due to time consuming, serious training and \nmultiple information requirements (Kobak et al. 2004). \nDespite advancements in neurobiological studies that \nenhance our understanding of the biological foundations \nof psychiatric disorders, they have not yielded sufficient \nbiomarkers to enhance the objectivity of psychiatric \nPsychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499 https://doi.org/10.24869/psyd.2023.489 \x08\nOriginal paper\n© Medicinska naklada – Zagreb, Croatia\nA NEW ARTIFICIAL INTELLIGENCE-BASED \nCLINICAL DECISION SUPPORT SYSTEM FOR \nDIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES \nBASED ON VOICE ANALYSIS\nNeslihan Cansel1, Ömer Faruk Alcin2, Ömer Furkan Yılmaz3, Ali Ari4, \nMustafa Akan5 & İlknur Ucuz6\n1 Assoc. Prof. Dr., Department of Psychiatry, Inonu University, Faculty of Medicine, Malatya, Turkey\n2 Assoc. Prof. Dr., Department of Software Engineering, Inonu University, Faculty of Engineering, Malatya, Turkey\n3 MD, Department of Psychiatry, Yeşilyurt Hasan Çalik Hospital, Malatya, Turkey\n4 Assist. Prof. Dr., Department of Computer Engineering, Inonu University, Faculty of Engineering, Malatya, Turkey\n5 Assist. Prof. Dr., Department of Psychiatry, Turgut Özal University, Faculty of Medicine, Malatya, Turkey\n6 Assoc. Prof. Dr., Department of Child and Adolescent Psychiatry, Inonu University Faculty of Medicine Malatya, Turkey\nreceived: 19. 04. 2023;\u2003 \u2003 \u2003 \u2003 revised: 24. 05. 2023;\u2003 \u2003 \u2003 \u2003 accepted: 31. 08. 2023\nSummary\n\t\nBackground: Speech features are essential components of psychiatric examinations, serving as important markers in the rec\xad\nognition and monitoring of mental illnesses. This study aims to develop a new clinical decision support system based on artificial \nintelligence, utilizing speech signals to distinguish between bipolar, depressive, anxiety and schizophrenia spectrum disorders.\n\t\nSubjects and methods: A total of 79 patients, who were admitted to the psychiatry clinic between 2020-2021, including 15 \nwith schizophrenia spectrum disorders, 24 with anxiety disorders, 25 with depressive disorders, and 15 with bipolar affective disorder, \nalongside with 25 healthy individuals were included in the study. The speech signal dataset was created by recording participants’ \nreadings of two texts determined by the Russell emotion model. The number of speech samples was increased by using random sam\xad\npling in speech signals. The sample audio signals were decomposed into time-frequency coefficients using Wavelet Packet Transform \n(WPT). Feature extraction was performed using each coefficient obtained from both Mel-Frequency Cepstral Coefficients (MFCC) and \nGammatone Cepstral Coefficient (GTCC) methods. The disorder classification was carried out using k-Nearest Neighbor (kNN) and \nSupport Vector Machine (SVM) classifiers. \n\t\nResults: The success rate of the developed model in distinguishing the disorders was 96.943%. While the kNN model exhibited \nthe highest performance in diagnosing bipolar disorder, it performed the least effectively in detecting depressive disorders. Whereas, \nthe SVM model demonstrated close and high performance in detecting anxiety and psychosis, but its performance was low in identify\xad\ning bipolar disorder.\nThe findings support the utilization of speech analysis for distinguishing major psychiatric disorders. In this regard, the future develop\xad\nment of artificial intelligence-based systems has the potential to enhance the psychiatric diagnosis process.\nKeywords: Artificial intelligence, mental illness, psychiatry, speech signal, Russel emotion model.\n* * * * *\n\n490\nassessment (Insel & Landis 2013). Consequently, there \nis a need for new approaches. In this regard, significant \nadvancements in computer technology have revolution\xad\nized the field of psychiatry, similar to other medical disci\xad\nplines, by enabling the detection of disorder-specific fea\xad\ntures and facilitating the prediction of treatment response \nand prognosis (Siena et al. 2020, van der Sluis et al. 2011, \nMarmar et al. 2019, Hoque et al. 2009, Bzdok D & Mey\xad\ner-Lindenberg A 2018).\nSpeech is a parameter that is frequently examined \nin this field. The reasons for this preference could be at\xad\ntributed to its advantages such as containing numerous \nclinical clues, difficulty in concealing verbal and non-ver\xad\nbal features of the person during speaking, direct expres\xad\nsion of emotions and thoughts through language, and in\xad\ndirect reflection of neuromuscular modulation. Economic \nfactors, availability, and low cost are also among the mo\xad\ntivations for this preference (Bedi et al. 2015; Low et al. \n2020, Yünden 2022).\nIn recent years, a significant number of studies have \ndemonstrated that speech patterns and features collect\xad\ned through mobile devices and sensors can serve as \nbiomarkers for early diagnosis and monitoring of men\xad\ntal disorders (van der Sluis et al. 2011, Cannizzaro et al. \n2004, Pan et al. 2019, Hashim et al. 2017, Karam et al. \n2014, Marmar et al. 2019, Hoque et al. 2009, de Boer \net al. 2020, Siena et al. 2020). For instance, Hashim et \nal. suggested that changes in speech signals consisting \nof acoustic features which characterize specific spectral \nand timing properties can be used in monitoring severity \nof depressive symptoms and treatment response (Hashim \net al. 2017). Faurholt-Jepsen et al. analyzed smartphone \nand self-monitored data over a period of 12 weeks, \ndemonstrating the importance of voice in distinguishing \naffective fluctuations, depression, and manic symptoms \n(Faurholt-Jepsen et al. 2016). Mota et al successfully \nmeasured dysfunctional thought flow such as divergence \nand recurrence in the speech of a group of psychotic pa\xad\ntients can be objectively measured by speech graph anal\xad\nysis (Mota et al. 2012). \nThe fact that most of the studies are based on a single \ndisease group may lead to a decrease in the general use \nof the obtained objective markers and consequently limit \ntheir reliability. To the best of our knowledge, there is no \nexisting study in the literature that distinguishes between \nthe main psychiatric disorder groups using voice analysis.\nTherefore, in this study, it is aimed to develop an arti\xad\nficial intelligence-based clinical decision support system \n(CDSS) with high accuracy, sensitivity, specificity by \nusing speech analysis which distinguishes patients with \nfour main psychiatric disorders including schizophrenia \nspectrum, depressive, and bipolar affective disorders and \nhealthy individuals. \nSUBJECTS AND METHODS\nThis is a cross-sectional study that received prior ap\xad\nproval from the local ethics committee (2020/25). The \nstudy included patients who admitted to the psychiatry \noutpatient clinic of Inonu University Faculty of Medicine \nbetween March 2020 and January 2021 and were diag\xad\nnosed with Anxiety Disorders, Bipolar Disorder, Depres\xad\nsive Disorders, Schizophrenia Spectrum Disorders (SSD) \nand followed up according to DSM-5 diagnostic criteria \n(American Psychiatric Association 2013). Patients eval\xad\nuated by two psychiatrists in accordance with the DSM-\n5 criteria and diagnoses which were confirmed by psy\xad\nchometric scales were invited to the study. Their voices \nwere recorded using an android smartphone (Samsung \nGalaxy S8, Samsung Electronics, 2017, South Korea). \nPsychiatric symptoms were assessed using scales with \nproven validity and reliability in Turkey, including the \nNegative Syndrome Scale (SANS) (Erkoç et al. 1991a) \nand Positive Symptoms Rating Scale (SAPS) for schizo\xad\nphrenia spectrum disorders (Erkoç et al. 1991b), Hamil\xad\nton Anxiety Rating Scale (HAM-A) for anxiety disorders \n(Yazıcı et al. 1998), Hamilton Depression Rating Scale \n(HAM-D) for depressive disorders (Akdemir et al. 1996), \nand Young Mania Rating Scale (YMRS) for bipolar af\xad\nfective disorder (Karadag et al. 2001). Demographic and \nclinical characteristics such as age, gender, marital status, \nduration of psychiatric illness, and use of psychotropic \ndrugs were recorded.\nA control group was selected, matching the patient \ngroups in terms of age, and consisting of individuals who \nwere evaluated by the same psychiatrists. These indi\xad\nviduals underwent a semi-structured interview and were \ndetermined not to meet any psychiatric disorders criteria \naccording to DSM-5. It was ensured that the healthy indi\xad\nviduals had not received treatment for any mental illness\xad\nes previously. Furthermore, participiants with conditions \nor history such as voice impairment or alteration due to \ndiseases (reflux, pharyngitis, etc.) or surgeries, voice or \ndiction training, speech disorders (stuttering, dysarthria), \nneurological diseases, intellectual disability causing cog\xad\nnitive impairment, or inability to speak Turkish were ex\xad\ncluded from the study. Participation was voluntary, and \nwritten consent was obtained.\nDuring the data collection period, the researcher re\xad\nsponsible for the analysis did not have access to the col\xad\nlected data.\nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\n\n491\nData Collection \nData collection involved obtaining voice signals \nfrom the participants reading two texts provided to them. \nThese texts were selected using The Russel Arousal-Va\xad\nlence emotion model in order to minimize any possible \nemotional impact (Figure 1). The model involves pre\xad\nsenting a stimulus to the subjects first and followed by \nan self-evaluation of the emotion created by this stimulus \nwith the Self-Assessment Manikin Questionnaire (SAM) \n(Russell 2003, Alakus et al. 2020). According to SAM, \ntexts corresponding to zone 4th (relaxed, peaceful, calm) \nwere considered neutral stimulus. Initially, 10 texts were \nchosen, and each text was read by the researchers. Two \ntexts that corresponded to the 4th region were selected for \nthe study (Figure 1).\nThe 2 texts determined using this method are as fol\xad\nlows:\nText 1. \x07“BUTTERFLY VALLEY: Fethiye is a paradise \ngarden that can be accessed from the Dead Sea \n(Blue Lagoon) by boats. It brings many people to\xad\ngether and has a unique magic. It is also famous \nfor its waterfalls and the tiger-patterned butter\xad\nflies found only in this region. “\nText 2. \x07“THE DECLARATION OF REPUBLIC: With \nthe acceptance of the constitutional amendment \nproposal prepared by Mustafa Kemal at Turkey’s \nGrand National Assembly in its second period, 29 \nOctober 1923, it is determined that the form of \ngovernment in Turkey is a republic.\nSpeech Signals Analyze and \nClassification Methods\nSpeech signals possess a complex structure that con\xad\ntains valuable information. However, in order to utilize \nthese signals, they must undergo a series of preprocess\xad\ning steps, such as enhancing signal quality, emphasizing \nrelevant components, suppressing external noises, and \ndetermining appropriate sampling values. Following this \npreprocessing stage, the next step is to extract features \nfrom the speech signals. Feature extraction involves \nidentifying characteristic values that describe the speak\xad\ners and can be used for subsequent recognition. The fea\xad\ntures extracted from the audio signals can be classified \ninto acoustic, linguistic, contextual, and hybrid features, \nwhich combine different sets of features. Acoustic fea\xad\ntures are often preferred in studies as they provide more \nobjective insights into sound production and signal struc\xad\nture. Commonly used acoustic features include intona\xad\ntion, formant frequencies, speech rate, sound quality, and \nfeatures based on Mel-Frequency Cepstral Coefficients \n(MFCC) (Özseven 2019, Eskidere & Ertaş 2009). \nIn this study, the speech signals also underwent a se\xad\nries of preprocessing steps, including screening and de\xad\ntermination of sampling values. Subsequently, they were \ntransformed into the time-frequency domain using the \nWavelet Packet Transform (WPT) process. The speech \nfeatures within the transformed signals were computed \nusing the MFCC and Gammatone Cepstral Coefficient \n(GTCC) methods. To classify the extracted features ac\xad\ncording to disease groups, Support Vector Machines \n(SVM) and k-Nearest Neighbor (kNN) methods were \nemployed. The following sections provide a brief expla\xad\nnation of these methods.\nWavelet Packet Transform \nThe wavelet transform is a useful tool for the short-\ntime analysis of speech signals, particularly those that are \nquasi-stationary. The key aspect of the wavelet transform \nis to analyze a signal considering scale. This scaling ap\xad\nproach enables both locality and spectral analysis, pro\xad\nviding a time-frequency representation. There are various \ntype of wavelet transforms such as discrete wavelet trans\xad\nform and WPT. Discrete wavelet transform is suitable for \nanalyzing low-frequency signals, yet it exhibits relatively \nlow resolution in the high frequency region. On the other \nhand, WPT can analyze a signal containing low, mid, and \nhigh-frequency components similarly to the speech sig\xad\nnals (Burrus et al. 1998, Gao & Yan 2011). This feature \nmade WPT to commonly used for detecting and distin\xad\nguishing transients with high frequency characteristics.\nFigure 1. Russel Arousal-Valence emotion model\nAnnoying\nAngry\nNervous\nSad\nBored\nSleepy\nCalm\nPeaceful\nRelaxed\nValence\nPleased\nHappy\nExcited\nArousal\n(high)\n(negative)\n(positive)\n(low)\n2\n3\n1\n4\nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\n\n492\nMel Frequencies Cepstral Coefficient \nMel Frequencies Cepstral Coefficient is a method \nused to detect and characterize speech-specific attributes \nin speaker verification systems. MFCC is a representation \nof the short-term power spectrum of a sound, based on a \nlinear cosine transform of a log power spectrum on a non\xad\nlinear Mel scale of frequency. By dividing the speech into \nsmall frames based on the number of input rows, window \nlength, and overlap length, MFCC computes cepstral fea\xad\ntures for each frame. One of the most significant features \nof MFCC is its ability to mimic the frequency selectivity \nof the human ear, enabling the extraction of distinctive \nand highly performant values (Hossan et al. 2010, Dim\xad\nitrov 2005).\nGammatone Cepstral Coefficient\nGammatone Cepstral Coefficients (GTCC) are a fea\xad\nture extraction technique widely used in speech and audio \nsignal processing. Although, GTCC feature extraction is \nsimilar to MFCC, the Gammatone Cepstral Coefficient \n(GTCC) adopts a frequency scale that has been ana\xad\nlytically devised, showcasing a more refined behavior \ncompared to the Mel-scale. The impulse response of the \nGammatone filter is derived from a combination of the \nGamma distribution function and a sinusoidal tone with a \nspecific frequency positioned at its center. Hence, by uti\xad\nlizing the Gammatone filter, the GTCC not only enhanc\xad\nes the representation of auditory signals but also demon\xad\nstrates the ability to capture the nuances of the human \nauditory system with greater fidelity than MFCC ( Balli \n2022, Valero\xa0&\xa0\xa0Alias 2012),\nk-Nearest Neighbor\nThe k-NN algorithm, a non-parametric learning al\xad\ngorithm, is widely used among machine learning meth\xad\nods due to its simplicity and good performance (Cover \n& Hart 1967). The k-NN method determines the class to \nwhich a new observation belongs by utilizing the obser\xad\nvation values in a sample set with predefined classes. In \nthis algorithm, the distance between the new data and the \nrecognized data is calculated for k points, and the new \ninformation is classified based on this distance (Ozkan \n2016). \nSupport Vector Machines\nSVM is an important and efficient supervised classi\xad\nfication algorithm. The essence of the algorithm is based \non detecting a hyperplane in a high-dimensional space \nthat maximally separates the different classes. When a \nlinearly separable dataset is provided to the system by \nbinary classification, an infinite number of hyperplanes \nare formed that can separate the input set. SVM con\xad\nstructs a decision plane to maximize the distance be\xad\ntween the two classes. This decision plane allows for \nthe classification of objects with different class mem\xad\nberships, and SVM finds the best hyperplane with the \nmaximum margin to separate them (Tekerek 2019, Siuly \net al. 2020). \nStatistical Analysis\nSPSS 22 (Statistical Package for Social Sciences; \nSPSS Inc., Chicago, IL) package program was used to \nanalyze the data of the participants. Among the descrip\xad\ntive data in the study, qualitative variables were shown \nas number and percentage (n and %), and quantitative \nvariables as mean±standard deviation (Mean±SD) values. \nIndependent sample t-test was used to compare the age \ndistribution between the groups. A value of p<0.05 was \nconsidered statistically significant.\nRESULTS\nSociodemographic Features\nOne hundred four participants were included in the \nstudy. Fifteen of the participants had a diagnosis of SSD, \n24 had an anxiety disorder, 25 had major depressive dis\xad\norder, 15 had a diagnosis of bipolar affective disorder. \nThe control group was consisted of 25 healthy individ\xad\nuals. The mean age of the participants was 36.53±13.10 \nyears and there was no statistical difference between the \ngroups (p=0.129). It was found that, the mean SANS to\xad\ntal score was 27.3±21.02 and the mean SAPS score was \n19.46±20 in the SSD patients. The mean HAM-A score \nwas 22.3±9.6 in the anxiety group, the mean HAM-D \nscore was 15.3±5.7 in the depressive group, and the mean \nYMRS total score was 14.5±7.9 in the bipolar group. The \nsociodemographic characteristics of the participants were \ngiven in Table 1.\nDesign of Speech Analysis Clinical \nDecision Support System\nThe proposed method aims to detect bipolar, depres\xad\nsive, anxiety, and schizophrenia spectrum disorders from \nspeech signals. Participants were instructed to read the \ntwo texts mentioned above once. Recordings were exclud\xad\ned from the analysis if there was unwanted background \nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\n\n493\nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\nTable 1. Sociodemographic and clinical features of the participants\nVariable\nSSD group\nAnxiety \ngroup\nDepressive \ngroup\nBipolar \ngroup\nHealthy \ncontrols\nAge (mean±SD)\n36.5±13.1\n35.2±11.3\n37.5±11.0\n35.6±11.0\n29.8±8.1\nPsychiatric onset age (mean±SD)\n24.3±6.9\n30.4±9.6\n30.9±10.1\n24.3±7.2\n-\nn (%) \nGender \nFemale\nMale\n6 (40)\n9 (60)\n20 (83.3)\n4 (16.7)\n22 (88)\n3 (12)\n13 (86.7)\n2 (13.3)\n17 (68)\n8 (32)\nPlace of birth Province\nDistrict\nVillage\n11 (73.3)\n3 (20)\n1 (6.7)\n18 (75)\n5 (20.8)\n1 (4.2)\n14 (56)\n7 (28)\n4 (16)\n8 (53.3)\n6 (40)\n1 (6.7)\n20 (80)\n3 (12)\n2 (8)\nEducation \nlevel\nPrimary \nHigh school\nUniversity\n4 (26.7)\n6 (40)\n5 (33.3)\n7 (29.2)\n8 (33.3)\n9 (37.5)\n13 (52)\n4 (16)\n8 (32)\n5 (33.3)\n5 (33.3)\n5 (33.3)\n0\n5 (20)\n20 (80)\nProfession \nUnemployed \nWorker\nOfficer\nOther\n10 (66.7)\n0\n5 (33.3)\n0\n17 (70.8)\n1 (4.2)\n4 (16.7)\n2 (8.3)\n19 (76)\n4 (16)\n2 (8)\n0\n11 (73.3)\n1 (6.7)\n2 (13.3)\n1 (6.7)\n12 (48)\n3 (12)\n10 (40)\n0\nMarital status Single\nMarried \nWidow/Divorced\n11 (73.3)\n3 (20)\n1 (6.7)\n7 (29.2)\n15 (62.5)\n2 (8.3)\n6 (24)\n18 (72)\n1 (4)\n5 (33.3)\n7 (46.7)\n3 (20)\n14 (56)\n11 (44)\n0\nEconomic \nLevel \n0-2000\n2000-5000\n>5000\n8 (53.3)\n1 (6.7)\n6 (40)\n10 (41.7)\n0\n14 (58.3)\n16 (64)\n2 (8)\n7 (28)\n12 (80)\n0\n3 (20)\n11 (44)\n0\n14 (56)\nLiving place \nProvince\nDistrict\nVillage\n15 (100)\n0\n0\n21 (87.5)\n1 (4.2)\n2 (8.3)\n23 (92)\n1 (4)\n1 (4)\n10 (66.7)\n3 (20)\n2 (13.3)\n20 (80)\n3 (12)\n2 (8)\nChronic \ninternal \ndisease history \nNo\nYes\n13 (86.7)\n2 (13.3)\n16 (66.7)\n8 (33.3)\n22 (88)\n3 (12)\n14 (93.3)\n1 (6.7)\n20 (80)\n5 (20)\nAlcohol-\n‑substance use \nhistory \nNo\nYes\n14 (93.3)\n1 (6.7)\n23 (95.8)\n1 (4.2)\n25 (100)\n0\n13 (86.7)\n2 (13.3)\n25 (100)\n0\nHistory of \nsmoking \nNo\nYes\n9 (60)\n6 (40)\n16 (66.7)\n8 (33.3)\n15 (60)\n10 (40)\n9 (60)\n6 (40)\n 22 (88)\n3 (12)\nCurrent \ncomplaints \nstart time\n> 1 month\n1-6 months\n6 months-1 year\n> 1 year\nRemission\n2 (13.3)\n1 (6.7)\n4 (26.7)\n5 (33.3)\n3 (20)\n4 (16.7)\n11 (45.8)\n2 (8.3)\n7 (29.2)\n0\n0\n9 (36)\n7 (28)\n9 (36)\n0\n3 (20)\n8 (53.3)\n2 (13.3)\n2 (13.3)\n0\n-\nDrug \ncurrently used \nNone\nOnly AP\nOnly SRI/SNRI\nOnly MSD\nSSRI+AP\nAP+MSD\n1 (6.7)\n12 (80)\n0\n0\n1 (6.7)\n1 (6.7)\n3 (12.5)\n1 (4.2)\n19 (79.2)\n0\n1 (4.2)\n0\n6 (24)\n1 (4)\n13 (52)\n0\n4 (16)\n1 (4)\n0\n1 (6.7)\n0\n3 (20)\n0\n11 (73.3)\n-\nAP: Antipsychotic, SSRI: Selective Serotonin Reuptake Inhibitor; SNRI: Serotonin-Noradrenaline Reuptake inhibitor, MSD: \nMood-Stabilizing Drugs, SSD: Schizophrenia Spectrum Disorders\n\n494\nnoise or if the speech was not clearly understandable. As \na result, a dataset consisting of 193 speech signals was \ncreated, involving 104 participants. The speech signals \nwere recorded at a sampling frequency of 44,100Hz, and \nthe overall speech record, which lasted an average of 30 \nseconds, contained approximately one million samples.\nIn the experiments, the number of speech signals was \nincreased by a random subsampling approach. through \ndata augmentation, 100,000 samples were randomly \nselected from each speech signal, and this process was \nrepeated ten times. Consequently, an augmented data\xad\nset of 1,930 sampled data points was obtained from the \noriginal data. The augmented data set was transformed \ninto time-frequency coefficients using WPT with four \nlevels. Thus, time-frequency coefficients with distinctive \nspeech signal clips were obtained. The parameters of the \nWPT method, including Shannon entropy and the db3 \nwavelet family, were chosen heuristically. Sixteen (2-level) \ntime-frequency coefficients are obtained with four-level \nWPT. Distinctive features were calculated from the WPT \ncoefficients of the speech signals using the MFCC and \nGTCC methods. A 1x28 feature vector, consisting of four\xad\nteen MFCCs and fourteen GTCCs, was formed from each \nWPT coefficient Considering all the WPT coefficients, a \n1,930x448-dimensional feature vector was ultimately ob\xad\ntained. Subsequently, k-NN and SVM classifiers were \nemployed to detect disorders based on the obtained fea\xad\ntures. For kNN, the parameters were determined exper\xad\nimentally, taking into account the lowest error rate, the \nEuclidean distance metric, and k=3.\nThe linear kernel in SVM kernel functions are used \nbecause of providing the best results compared to oth\xad\ner kernel functions. All experiments were carried out in \nMATLAB environment on a computer equipped with a \n2.70 GHz CPU processor and 32 GB RAM. The algo\xad\nrithm of the proposed method were given in Figure 2.\nExperimental Results\nTo evaluate the performance of the proposed method, \naccuracy (Acc.), sensitivity (Sens.), specificity (Spec.), \nprecision (Prec.), F1-score, MCC, and kappa metrics, \nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\nFigure 2. The proposed framework for detection psychiatric disorders from speech signal\nSpeech Signals \nRandom Subsampling\nClassification \nSVM & KNN\nFeature Extraction\nMFCC & GTCC\nWavelet Packet Transform\n\n495\nwhich are widely used in biomedical applications were \nused. Five-fold cross-validation was used to validate the \nproposed method. Accuracy represents the ability to give \nthe same value during repeated measurements of phys\xad\nical size. Sensitivity indicates the ability of a classifica\xad\ntion model to correctly identify positive instances from \nall the actual positive instances. Conversely, specificity \nrefers to the ability of a model to find actual healthy indi\xad\nviduals among undiagnosed individuals. Precision is the \nproportion of correctly predicted positive instances out \nof all instances predicted as positive. F1-score value is \nthe harmonic mean of precision and recall values. Kappa \nparameter indicates the agreement between observed and \nexpected values and ranges from -1 to +1. A high kappa \nvalue implies that the evaluated model is performing well \nand shows a strong agreement with the reference. Hence\xad\nforward, kappa values close to 1 were used for our model. \nThe performance parameters of the SVM classifier \nwere calculated as 96.477% accuracy, 96.051% sensitiv\xad\nity, 99.110% specificity, 96.338% precision, F1 score of \n0.962, MCC value of 0.953, and kappa value of 0.890. The \nperformance parameters of the kNN classifier were calcu\xad\nlated as 96.943% accuracy, 96.930% sensitivity, 99.228% \nspecificity, 96.802% precision, F1 score of 0.969, MCC \nvalue of 0.961 and kappa value of 0.904. These results of \nthe proposed system are showed in Table 2.\nAlthough the performance parameters of the two clas\xad\nsifiers seem to be close to each other, kNN performed \nslightly better than SVM. Experimental analysis was pro\xad\nceeded by drawing the Receiver Operating Characteristic \n(ROC) curves. The ROC curve helps to evaluate the over\xad\nall classifier performance. The ROC curves were shown \nin Figure 3 for the kNN, and in Figure 4 for the SVM \nclassifier.\nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\nTable 2. Performance results of the proposed methods\nMethod\nAcc. (%)\nSens. (%)\nSpec. (%) Prec.(%)\nF1-score\nMCC\nKappa\nSVM\n 96.477 \n 96.051 \n 99.110 \n 96.338\n 0.962\n 0.953\n 0.890\nkNN\n 96.943 \n 96.930 \n 99.228 \n 96.802\n 0.969\n 0.961\n 0.904\nFigure 3. ROC curve for \nkNN classifier \nFalse Positive Rate\n0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nTrue Positive Rate\nROC curve for kNN\nAnxiety\nBipolar\nDepression\nControl\nPsychosis\n\n496\nWhen examining the ROC curve in Figure 3, kNN \nwas the most successful method in distinguishing the \ncontrol group from the patient group. However, the kNN \nmodel performed lower than other methods in detecting \ndepression. On the other hand, the SVM model distin\xad\nguishes the control group better, as well as the kNN mod\xad\nel. While SVM showed a close performance resemblance \nin detecting anxiety and psychosis, it displayed lower \nperformance in bipolar detection (Figure 4).\nDISCUSSION\nIn this study, an artificial intelligence-based clinical \ndecision support system was developed with a perfor\xad\nmance of 96.943% to detect bipolar disorder, depres\xad\nsive, anxiety, and schizophrenia spectrum disorders from \nsound signals and distinguish them from the healthy con\xad\ntrol group.\nVarious studies in the literature have shown that voice \nanalysis can be used for clinical classification in differ\xad\nent patient groups. For example, Tahir et al. classified \nschizophrenia patients and healthy controls with 81.3% \naccuracy using non-verbal language measures (Tahir et \nal. 2019). Martínez-Sánchez et al., were able to distin\xad\nguish schizophrenic patients from healthy controls with \nover 90% sensitivity, specificity and overall accuracy, \nthanks to the method they developed using the prosodic \nand phonetic sound features determined while reading a \ntext (Martínez-Sánchez et al. 2015). By examining the \nsounds obtained from patients’ videotapes, Cannizzaro \net al. obtained data indicating that motor timing param\xad\neters reflecting speech production (for example, speech \nrate and pause time) and frequency modulation (for ex\xad\nample, pitch variability) were significantly associated \nwith the severity of depression (Cannizzaro et al. 2004). \nSimilarly, Maxhuni et al. in their study followed bipolar \npatients with a smartphone-based system and classified \ntheir mood transitions at a rate higher than 80% by us\xad\ning the speech, accelerometer and self-assessment-relat\xad\ned data obtained from daily phone calls (Maxhuni et al. \n2016).\nIn our study, unlike these studies that focused on a \nsingle disorder sample, we created a CDSS that covers \nfour main disorders groups and obtained 448 different \nfeatures from the audio signals to develop this system. \nThis allowed for more sophisticated separations and \npromising clinical use of the model. It should be noted \nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\nFalse Positive Rate\n0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nTrue Positive Rate\nROC curve for SVM\nAnxiety\nBipolar\nDepression\nControl\nPsychosis\nFigure 4. ROC curve for \nSVM classifier\n\n497\nthat most previous studies used data from daily conversa\xad\ntions and interviews, which could involve possible emo\xad\ntional manipulations. In our study, we provided a neu\xad\ntral stimulus using the Russell Arousal-Valence emotion \nmodel, resulting in a more objective dataset. With ran\xad\ndom sampling, the number of samples was increased, so \nthat the developed artificial-intelligence model learned \nfrom more samples and its classification performance \nwas increased (Jiao et al. 2018, Aggarwal 2019). By de\xad\ncomposing the augmented dataset into four levels using \nWPT and extracting distinctive features using MFCC and \nGTCC methods, we developed a method with a success \nrate of 96.943%. This result indicated a considerably \nhigher performance compared to studies that partially \nincluded a small number of patients, mostly used only \none type of data, and did not consider more than two dis\xad\norders at the same time. Furthermore, we tested existing \nclassifiers and determined which disorders the machine \nlearning models were more specific for. As an illustra\xad\ntion, the kNN model exhibited superior performance \nin identifying bipolar disorder, but it demonstrated the \nleast effective performance in detecting depression. On \nthe other hand, the SVM model demonstrated a strong \nand comparable performance in distinguishing between \nanxiety and SSD, although its performance in detecting \nbipolar disorders was comparatively lower than that of \nthe other groups.\nWhile this study contributes valuable insights, it is \nimportant to address certain limitations that should be \ntaken into consideration. First, participation in the re\xad\nsearch was dependent on voluntary, and as a result, the \nsample size remained relatively low. Additionally, all \nof the participants resided in the same region and had \nsimilar cultural and linguistic characteristics. Therefore, \nalthough the developed method has shown an effective \nperformance for this data set, it is unknown whether \nthe obtained results can be generalized to a new sample \nwith different ages, geography, socioeconomic levels, \nand registration types. Second, the small sample size \nprevented the differentiation of variables that could im\xad\npact the voice structure, such as gender (length of vocal \ncords and speech patterns, as well as acoustic charac\xad\nteristics like duration, intensity, and frequency of voice \nand speech signals, which may differ between genders), \nsmoking (which can change the acoustic properties of \nthe voice by causing histological changes on the vocal \nfold epithelium), and the type of psychotropic treatment \n(which may cause impairment in speech-related motor \nfunctions). Third, subgroups (delusional disorder, schi\xad\nzoaffective disorder, obsessive compulsive disorder, \nphobias, panic disorder, dysthymia etc) were not ana\xad\nlyzed, and patient groups were grouped based on the core \nsymptoms. Consequently, it remains unclear whether the \nmodel would be effective in distinguishing subgroups. \nFourth, although neuropsychological deficiencies that \nmay affect acoustic or lexical expression were assessed \nbased on history, neuropsychological tests were not em\xad\nployed to detect these conditions. Finally, considering \nthe depth and obscurity of the human psyche, it may not \nbe ethically appropriate to rely solely on sound features \nfor a “definitive” diagnosis. In the future, multicenter \nstudies that would be conducted in large populations and \nthat evaluate more markers together could provide more \nreliable results. \nDespite all these limitations, our study is the first to \nutilize machine learning methods distinguishing four dif\xad\nferent main psychiatric disorders and healthy person and \nmay lead to future studies. Considering the performance \nparameters, the developed method can be employed by \nexperts as an effective and reliable tool to assist in di\xad\nagnosing mental illnesses, thereby contributing to effi\xad\nciency in terms of speed and time. The CDSS may be \nbeneficial for patients to be evaluated more objectively, \nindependent of factors such as the evaluator’s experience, \nattention, and mood, as well as the partially low-reliabil\xad\nity of self-report measures. Furthermore, it can also be \napplied to assess specific populations, such as children or \nthe elderly, who may encounter difficulties in expressing \nthemselves. Additionally, it can be employed for monitor\xad\ning patients undergoing extreme circumstances, such as \ndisasters, wars, or pandemics, where regular check-ups \nmay be hindered. \nCONCLUSION\nIn this study, a new artificial intelligence-based meth\xad\nod was presented, which achieves a performance param\xad\neter above 96.943% and can automatically and accurately \nclassify psychiatric disorders from healthy controls. The \nkNN model demonstrated high performance, particular\xad\nly in diagnosing bipolar disorder, while the SVM model \nshowed comparable high performance in distinguishing \nanxiety and SSD. The developed method holds the poten\xad\ntial to assist psychiatrists in efficiently and reliably distin\xad\nguishing their patients. \nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\n\n498\nAcknowledgements: None.\nEthical Considerations: Does this study include \nhuman subjects? YES\nAuthors confirmed the compliance with all relevant ethi\xad\ncal regulations.\nConflict of interest: No conflict of interest\nFunding sources: The authors received no funding \nfrom an external source.\nAuthors contributions: Neslihan cansel & İlknur \nUcuz: study design, statistical analysis, first draft. Ömer \nFurkan Yılmaz & Mustafa Akan: data collection. Ömer \nFaruk Alçin & Ali Arı: data analysis and development of \nclinic support system. All authors approval of the final \nversion.\nReferences\n1.\t Aggarwal SLP: Data augmentation in dermatology image \nrecognition using machine learning. Skin Research and \nTechnology 2019; 25: 815-820.\n2.\t Akdemir A, Örsel DS, Dağ İ, Türkçapar MH, İşcan N, Öz\xad\nbay H: Hamilton depresyon derecelendirme ölçeği (HD\xad\nDÖ)’nin geçerliliği-güvenirliliği ve klinikte kullanımı. Psi\xad\nkiyatri Psikoloji Psikofarmakoloji Dergisi 1996; 4: 251-259.\n3.\t Alakus TB, Gonen M, Turkoglu I: Database for an emotion \nrecognition system based on EEG signals and various com\xad\nputer games–GAMEEMO. Biomed Signal Process Control \n2020; 60: 101951.\n4.\t American Psychiatric Association: Diagnostic and Statisti\xad\ncal Manual of Mental Disorders 5. Washington, D.C., 2013.\n5.\t Balli O: Vücut Seslerinden Bölge Tanımlanması için İdeal \nKayıt Süresinin Belirlenmesinde MFCC ve GTCC Öznite\xad\nliklerinin Etkisinin Karşılaştırılması.” Avrupa Bilim ve Te\xad\nknoloji Dergisi 2022;43:36-40.\n6.\t Bedi G, Carrillo F, Cecchi GA, Slezak DF, Sigman M, Mota \nNB, et al.: Automated analysis of free speech predicts psy\xad\nchosis onset in high-risk youths. NPJ Schizophr 2015; 1: \n15030.\n7.\t Burrus CS, Gopinath RA, Guo H: Introduction to Wavelets \nand Wavelet Transforms, A Primer. Upper Saddle River, Nj, \nPrentice-Hall, 1998.\n8.\t Bzdok D & Meyer-Lindenberg A: Machine Learning for \nPrecision Psychiatry: Opportunities and Challenges. Biol \nPsychiatry Cogn Neurosci Neuroimaging 2018; 3: 223-230.\n9.\t Cannizzaro M, Harel B, Reilly N, Chappell P, Snyder PJ: \nVoice acoustical measurement of the severity of major de\xad\npression. Brain Cogn 2004; 56: 30-35.\n10.\t Cover T & Hart P: Nearest neighbor pattern classification. \nIEEE transactions on information theory 1967; 13: 21-27.\n11.\t de Boer JN, Brederoo SG, Voppel AE, Sommer IEC: Anom\xad\nalies in language as a biomarker for schizophrenia. Curr \nOpin Psychiatry 2020; 33: 212-218.\n12.\t Dimitrov Ganchev T: Speaker recognition. Unpublished \ndoctoral dissertation. Dept of Electrical and Computer En\xad\ngineering, University of Patras, Greece, 2005.\n13.\t Erkoç S, Arkonaç O, Ataklı C, Özmen E: Pozitif Semptom\xad\nları Değerlendirme Ölçeğinin güvenilirliğini ve geçerliliği. \nDüşünen Adam Dergisi, 1991a; 4: 20-24.\n14.\t Erkoç S, Arkonaç O, Ataklı C, Özmen E: Negatif Semptom\xad\nları Değerlendirme Ölçeğinin güvenilirliğini ve geçerliliği. \nDüşünen Adam Dergisi, 1991b; 4: 14-15.\n15.\t Eskidere Ö & Ertaş F: MEL Frekansı Kepstrum Kat\xad\nsayılarındaki Değişimlerin Konuşmacı Tanımaya Etkisi. \nUludağ Üniversitesi Mühendislik Fakültesi Dergisi. 2009; \n14(2): 93-110\n16.\t Faurholt-Jepsen M, Busk J, Frost M, Vinberg M, Chris\xad\ntensen EM, Winther O, et al: Voice analysis as an objective \nstate marker in bipolar disorder.\xa0Translational Psychiatry, \n2016; 6(7): e856 \n17.\t Gao, R.X., Yan, R. (2011). Wavelet Packet Trans\xad\nform. In: Wavelets. Springer, Boston, MA. https://doi.\norg/10.1007/978-1-4419-1545-0_5\n18.\t Hashim NW, Wilkes M, Salomon R, Meggs J, France DJ: \nEvaluation of Voice Acoustics as Predictors of Clinical De\xad\npression Scores. J Voice 2017; 31: 256.e1-256.e6.\n19.\t Hoque ME, Lane JK, El Kaliouby R, Goodwin M, Picard \nRW: Exploring speech therapy games with children on the \nautism spectrum. Proc Annu Conf Int Speech Commun As\xad\nsoc, INTERSPEECH, 2009.\n20.\tHossan MA, Memon S, Gregory MA: A novel approach for \nMFCC feature extraction. 4th Int Conf Signal Process Com\xad\nmun Syst IEEE, 2010; 1-5.\n21.\tInsel TR & Landis SC: Twenty-five years of progress: the \nview from NIMH and NINDS. Neuron 2013; 80: 561-567.\n22.\tJarman L, Martin A, Venn A, Otahal P, Blizzard L, Teale B \n& Sanderson K: Workplace Health Promotion and Mental \nHealth: Three-Year Findings from Partnering Healthy@\nWork. PloS 2016;1(8):e0156791. \n23.\tJiao Y, Tu M, Berisha V, Liss J: Simulating dysarthric \nspeech for training data augmentation in clinical speech \napplications. In IEEE international conference on acoustics, \nspeech and signal processing (ICASSP) 2018; 6009-6013.\n24.\tKaradağ F, Oral ET, Aran Yalçın F, Erten E: Young mani \nderecelendirme ölçeğinin Türkiye’de geçerlik ve güvenil\xad\nirliği. Türk Psikiyatri Dergisi 2001; 13: 107-14.\n25.\tKaram ZN, Provost EM, Singh S, Montgomery J, Archer \nC, Harrington G, et al.: Ecologically valid long-term mood \nmonitoring of individuals with bipolar disorder using \nspeech. Proc IEEE Int Conf Acoust Speech Signal Process \n2014; 2014: 4858-4862.\n26.\tKobak KA, Engelhardt N, Williams JB, Lipsitz JD: Rater \ntraining in multicenter clinical trials: issues and recom\xad\nmendations. J Clin Psychopharmacol 2004; 24: 113-117.\n27.\t Low DM, Bentley KH & Ghosh SS: Automated assessment of \npsychiatric disorders using speech: A systematic review. La\xad\nryngoscope Investigative Otolaryngology 2020: 5(1); 96–116\nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\n\n499\n28.\tMarmar CR, Brown AD, Qian M, Laska E, Siegel C, Li M, \net al.: Speech-based markers for posttraumatic stress disor\xad\nder in US veterans. Depress Anxiety 2019; 36: 607-616.\n29.\t Martínez-Sánchez F, Muela-Martínez JA, Cortés-Soto P, \nGarcía Meilán JJ os., Vera Ferrándiz JA ntoni., Egea Capar\xad\nrós A, et al.: Can the Acoustic Analysis of Expressive Prosody \nDiscriminate Schizophrenia? Span J Psychol 2015; 18: E86.\n30.\tMaxhuni A, Muñoz-Meléndez A, Osmani V, Perez H, May\xad\nora O, Morales EF: Classification of bipolar disorder epi\xad\nsodes based on analysis of voice and motor activity of pa\xad\ntients. Pervasive Mob Comput 2016; 31: 50-66.\n31.\tMota NB, Vasconcelos NA, Lemos N, Pieretti AC, Kinou\xad\nchi O, Cecchi GA et al.: Speech graphs provide a quan\xad\ntitative measure of thought disorder in psychosis. PLoS \n2012;7(4):e34928. \n32.\t Ozkan H: A comparison of classification methods for telediag\xad\nnosis of Parkinson’s disease. Entropy 2016:18(4);(2016):115\n33.\tÖzseven T: Konuşma Tabanlı Duygu Tanımada Ön İşleme \nve Öznitelik Seçim Yöntemlerinin Etkisi. Dicle Üniversite\xad\nsi Mühendislik Fakültesi Mühendislik Dergisi 2019; 10(1): \n99-112\n34.\tPan W, Flint J, Shenhav L, Liu T, Liu M, Hu B, et al.: Re-ex\xad\namining the robustness of voice features in predicting de\xad\npression: Compared with baseline of confounders. PLoS \nOne 2019; 14: e0218172.\n35.\tRegier DA, Narrow WE, Clarke DE, Kraemer HC, Kura\xad\nmoto SJ, Kuhl EA, et al.: DSM-5 field trials in the United \nStates and Canada, Part II: test-retest reliability of selected \ncategorical diagnoses. Am J Psychiatry 2013; 170: 59-70.\n36.\tRussell JA: Core affect and the psychological construction \nof emotion. Psychol Rev 2003; 110: 145-172.\n37.\tSiena FL, Vernon M, Watts P, Byrom B, Crundall D, Bree\xad\ndon P: Proof-of-Concept Study: a Mobile Application to \nDerive Clinical Outcome Measures from Expression and \nSpeech for Mental Health Status Evaluation. J Med Syst \n2020; 44: 209.\n38.\tSiuly S, Alcin OF, Kabir E, Sengur A, Wang H, Zhang Y, et \nal.: A New Framework for Automatic Detection of Patients \nWith Mild Cognitive Impairment Using Resting-State EEG \nSignals. IEEE Trans Neural Syst Rehabil Eng 2020; 28: \n1966-1976.\n39.\tTahir Y, Yang Z, Chakraborty D, Thalmann N, Thalmann D, \nManiam Y, et al.: Non-verbal speech cues as objective mea\xad\nsures for negative symptoms in patients with schizophrenia. \nPLoS One 2019; 14: e0214314.\n40.\t Tekerek A: Support Vector Machine Based Spam SMS De\xad\ntection. Politeknik Dergisi 2019;22 (3):779-784\n41.\t Valero X & Alias F: Gammatone Cepstral Coefficients: Bi\xad\nologically Inspired Features for Non-Speech Audio Classi\xad\nfication,” in IEEE Transactions on Multimedia. IEEE trans\xad\nactions on multimedia 2012; 14(6): 1684-1689.\n42.\t van der Sluis F, van den Broek E, Dijkstra T: Towards an \nartificial therapy assistant: Measuring excessive stress from \nspeech. In Traver V, Fred A, Filipe J, Gamboa H (eds): Pro\xad\nceedings of the International Conference on Health Informat\xad\nics, HealthInf, 357-363. INSTICC PRESS, Portugal, 2011. \n43.\t WHO:Mental Disorders. Available from: https://www.who.int/\nnews-room/fact-sheets/detail/mental-disorders. (accessed Ju\xad\nne 15, 2023)\n44.\t Yazıcı MK, Demir B, Tanrıverdi N, Karaoğlu E, Yolaç P: \nHamilton Anksiyete Değerlendirme Ölçeği, Değerlendir\xad\niciler Arası Güvenirlik ve Geçerlik Çalışması. Türk Psiki\xad\nyatr Derg 1998; 9: 114- 117.\n45.\t Young RC, Biggs JT, Ziegler VE, Meyer DA: A rating scale \nfor mania: Reliability, validity and sensitivity. Br J Psychia\xad\ntry 1978; 133: 429-435.\n46.\t Yünden S: Psikiyatrik Hastalıklarda Ses Analizi. Cur\xad\nrent Research and Reviews in Psychology and Psychiatry \n2022:2(2);201-216\nNeslihan Cansel, Ömer Faruk Alcin, Ömer Furkan Yılmaz, Ali Ari, Mustafa Akan & İlknur Ucuz: A NEW ARTIFICIAL INTELLIGENCE-\n‑BASED CLINICAL DECISION SUPPORT SYSTEM FOR DIAGNOSIS OF MAJOR PSYCHIATRIC DISEASES BASED \nON VOICE ANALYSIS\u2003 \u2003 \u2003 \u2003 Psychiatria Danubina, 2023; Vol. 35, No. 4, pp 489-499\nCorrespondence:\nİlknur Ucuz\nAssoc. Prof. Dr., \nDepartment of Child and Adolescent Psychiatry, \nInonu University Faculty of Medicine Malatya, Turkey, \nilknur_27@yahoo.com, +00905072383095, \nORCID id: 0000-0003-1986-4688.'}], 'model': 'academic-extractor', 'max_tokens': 4096, 'response_format': {'type': 'json_object'}}}
2026-01-02 12:58:04,326 - openai._base_client - DEBUG - Sending HTTP Request: POST http://localhost:11434/v1/chat/completions
2026-01-02 12:58:04,326 - httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=1000.0 socket_options=None
2026-01-02 12:58:04,327 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x70ddf346fd40>
2026-01-02 12:58:04,327 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-02 12:58:04,327 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-02 12:58:04,327 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-02 12:58:04,327 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-02 12:58:04,327 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-02 12:58:28,973 - httpcore.http11 - DEBUG - receive_response_headers.failed exception=KeyboardInterrupt()
2026-01-02 12:58:28,973 - httpcore.http11 - DEBUG - response_closed.started
2026-01-02 12:58:28,973 - httpcore.http11 - DEBUG - response_closed.complete
